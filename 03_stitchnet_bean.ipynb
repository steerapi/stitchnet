{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02463b7-9fb2-4fc9-b3d4-963da1093a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46146e10-04f2-4fa4-a001-24fdf1398844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skl2onnx.helpers.onnx_helper import load_onnx_model\n",
    "from stitchnet.stitchonnx.utils import Net\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "netsFiles = sorted(glob('_models/fragments/net*'))\n",
    "nets = []\n",
    "for i,netsFile in enumerate(netsFiles):\n",
    "    fragmentFiles = sorted(glob(str(Path(netsFile)/'fragment*.onnx')))\n",
    "    onnxFragments = []\n",
    "    for fragmentFile in fragmentFiles:\n",
    "        onnxFragment = load_onnx_model(fragmentFile)\n",
    "        onnxFragments.append(onnxFragment)\n",
    "    net1 = Net(onnxFragments, i)\n",
    "    nets.append(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd9e874-d12e-4744-8c34-f3ca6aa5e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.ones(1,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991aecb8-aee4-4bc0-a464-0b308014566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset beans (/home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742faefda4094be8b5ad110953ecc7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Loading cached shuffled indices for dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-cac060a5360da545.arrow\n",
      "Loading cached shuffled indices for dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-fb581327019d6d2b.arrow\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-5f0b2533f6c38720.arrow\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-940888201d588dc5.arrow\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-1ce4dec42b3db4e8.arrow\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/beans/default/0.0.0/90c755fb6db1c0ccdad02e897a37969dbf070bed3755d4391e269ff70642d791/cache-14bff30dd192ffba.arrow\n"
     ]
    }
   ],
   "source": [
    "from stitchnet.stitchonnx.utils import load_cats_and_dogs_dset,convert_imagenet_to_cat_dog_label\n",
    "from stitchnet.stitchonnx.utils import accuracy_score_model,accuracy_score_net,load_dl\n",
    "from stitchnet.stitchonnx.utils import generate_networks, ScoreMapper\n",
    "from stitchnet.stitchonnx.report import Report\n",
    "from stitchnet.stitchonnx.utils import evalulate_stitchnet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "random.seed(51)\n",
    "np.random.seed(24)\n",
    "torch.manual_seed(77)\n",
    "\n",
    "K = 4\n",
    "STITCH_BATCH_SIZE = 32 # todo study the effect\n",
    "MAX_DEPTH = 16\n",
    "THRESOULD = 0\n",
    "TOTAL_THRESOULD = 0.5\n",
    "\n",
    "RESULT_NAME = f\"{int(time.time())}_result_beans_CKA_BS_{STITCH_BATCH_SIZE}_MD_{MAX_DEPTH}_T_{THRESOULD}_TT_{TOTAL_THRESOULD}_K_{K}\"\n",
    "\n",
    "EVAL_BATCH_SIZE = 16\n",
    "\n",
    "from stitchnet.stitchonnx.utils import load_hf_train_val_dset_with_test_split\n",
    "\n",
    "dataset_train, dataset_val = load_hf_train_val_dset_with_test_split('beans', \n",
    "                                                                    train='validation', \n",
    "                                                                    val='test', \n",
    "                                                                    label='labels',\n",
    "                                                                    seed=47)\n",
    "\n",
    "# dl_score = load_dl(dataset_train, batch_size=STITCH_BATCH_SIZE)\n",
    "# data_score,t = next(iter(dl_score))\n",
    "# data_score = data_score.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fea5d502-fa2d-4d6f-a826-10f13a829191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 2,\n",
       "        0, 1, 1, 0, 0, 0, 2, 2, 1, 2, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 1, 2, 2, 0,\n",
       "        1, 1, 1, 0, 2, 0, 1, 1, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 1,\n",
       "        2, 0, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 0, 0, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1,\n",
       "        2, 1, 2, 2, 2, 1, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_train = dataset_train.shuffle(seed=47)\n",
    "dataset_train['labels'][0:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d39ea8a-e2c7-456e-a642-c627fd1b6619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train.add_column(name='label', column=dataset_train['labels'])\n",
    "# dataset_val.add_column(name='label', column=dataset_val['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c78895ea-4790-4f12-af05-b49a0578f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 17.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 3, 224, 224)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import AutoProcessor\n",
    "from tqdm import tqdm\n",
    "# p = AutoProcessor.from_pretrained('microsoft/resnet-50')\n",
    "inps = []\n",
    "# tgts = []\n",
    "# for x in tqdm(dataset_train.take(STITCH_BATCH_SIZE)):\n",
    "for x in tqdm(dataset_train.select(range(STITCH_BATCH_SIZE))):\n",
    "    try:\n",
    "        inps += x['pixel_values']\n",
    "        # inps += p(x['image'])['pixel_values']\n",
    "        # tgts += [x['label']]\n",
    "    except:\n",
    "        pass\n",
    "data_score = np.stack(inps)\n",
    "data_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb8f66-1631-4aa2-8648-7ad2faef9e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb5e71f2-1d9c-416f-b0ab-b90f1ebc76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(1)\n",
    "k = 0\n",
    "if os.path.exists(f'./_results/{RESULT_NAME}.txt'):\n",
    "    with open(f'./_results/{RESULT_NAME}.txt', 'r') as f:\n",
    "        k = len(f.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef687c5-6b30-4c10-8536-e0eb218da7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 27, 27)\n",
      "(32, 192, 13, 13)\n",
      "(32, 384, 13, 13)\n",
      "(32, 256, 13, 13)\n",
      "(32, 9216)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "current depth: 1\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 64, 56, 56)\n",
      "(32, 64, 224, 224)\n",
      "(32, 256, 56, 56)(32, 16, 56, 56)\n",
      "\n",
      "(32, 256, 56, 56)\n",
      "(32, 16, 56, 56)\n",
      "(32, 64, 112, 112)\n",
      "(32, 72, 28, 28)\n",
      "(32, 512, 28, 28)\n",
      "(32, 128, 112, 112)(32, 512, 28, 28)\n",
      "\n",
      "(32, 24, 28, 28)(32, 128, 56, 56)\n",
      "\n",
      "(32, 1024, 14, 14)\n",
      "(32, 256, 56, 56)\n",
      "(32, 96, 14, 14)\n",
      "(32, 1024, 14, 14)\n",
      "(32, 2048)(32, 256, 56, 56)\n",
      "(32, 1024)(32, 40, 14, 14)\n",
      "\n",
      "\n",
      "(32, 120, 14, 14)\n",
      "(32, 256, 28, 28)\n",
      "(32, 48, 14, 14)\n",
      "(32, 512, 28, 28)(32, 288, 7, 7)\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 96, 7, 7)\n",
      "(32, 576)\n",
      "(32, 1024)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 25088)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.67', '0.6', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.67', '0.6', '0.56']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.67', '0.6', '0.56']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.0031935760687087e-10 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.61', '0.56', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.61', '0.56', '0.54']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.61', '0.56', '0.54']\n",
      "totalscore 0.9999998211860728\n",
      "diff sampled tensor(0.0068)\n",
      "epoch 0 loss 4.3149970299819174e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.75', '0.7', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.75', '0.7', '0.69']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.75', '0.7', '0.69']\n",
      "totalscore 0.999999940395341\n",
      "diff sampled tensor(0.0978)\n",
      "epoch 0 loss 1.2652531056802654e-05 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.76', '0.76', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.76', '0.76', '0.73']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.76', '0.76', '0.73']\n",
      "totalscore 0.9999998807906998\n",
      "diff sampled tensor(0.1688)\n",
      "epoch 0 loss 2.545051375877928e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.94', '0.93']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.95', '0.94']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.95', '0.94']\n",
      "totalscore 0.9999998807906998\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.97', '0.85']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.97', '0.85']\n",
      "totalscore 0.9999998807906998\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.8']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.8']\n",
      "totalscore 0.9999998211860621\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 62.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net000\n",
      "totalscore 0.7950070744744253\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.7950070270883111\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 56.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net001\n",
      "totalscore 0.6270959423076422\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 71.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net002\n",
      "totalscore 0.9703022873041046\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 62.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net003\n",
      "totalscore 0.8492150486451118\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.9455450838154219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.9362932519562903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.7563530947951483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 256]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.7563530497129908\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 75.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net004\n",
      "totalscore 0.634605347196476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.85']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.85']\n",
      "totalscore 0.6157590554989404\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 75.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5369713403121087\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.6013216861884032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.6013216861884032\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 73.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.756169929732671\n",
      "epoch 0 loss 0.0 torch.Size([32, 256]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 74.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net007\n",
      "totalscore 0.7321692864793834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 256]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.83', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.83', '0.8']\n",
      "totalscore 0.7321691991980029\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 79.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7265625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net008\n",
      "totalscore 0.6062294115313278\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.5874024249972816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.5874024249972816\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 83.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7890625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net009\n",
      "totalscore 0.7483126375115976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 384]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.7483126375115976\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 94.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net010\n",
      "totalscore 0.6306328131967895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.6119064510594638\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 85.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5281433887142505\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.594925285401387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.81']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.81']\n",
      "totalscore 0.5949252499410767\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 102.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.7042412690684735\n",
      "epoch 0 loss 0.0 torch.Size([32, 384]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 103.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net013\n",
      "totalscore 0.6946055243124447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 384]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.97', '0.85']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.97', '0.85']\n",
      "totalscore 0.6946056071158758\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.85', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.8']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.8']\n",
      "totalscore 0.6946056071158758\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 99.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5522151126010044\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.8']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.8']\n",
      "totalscore 0.5522151126010044\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 88.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net015\n",
      "totalscore 0.6739752150678838\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 78.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net016\n",
      "totalscore 0.5904438176322858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.6141105524235613\n",
      "ERROR The size of tensor a (192) must match the size of tensor b (384) at non-singleton dimension 1\n",
      "totalscore 0.5602916741197284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (192) must match the size of tensor b (384) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 192]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.97', '0.85']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.97', '0.85']\n",
      "totalscore 0.5602915739317698\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.8']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.8']\n",
      "totalscore 0.5602915739317698\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 115.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5436560313227182\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 122.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8203125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net018\n",
      "totalscore 0.5420368586756652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 192]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 121.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net019\n",
      "totalscore 0.6705857515335083\n",
      "diff sampled tensor(32752340.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 1.652395829862478 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(32752342.)\n",
      "epoch 0 loss 1.652022055217198 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.57', '0.57', '0.52', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.57', '0.57', '0.52', '0.51']\n",
      "potential next fragments after thresholding of 0: 4 ['0.57', '0.57', '0.52', '0.51']\n",
      "totalscore 0.6029930114746094\n",
      "ERROR The size of tensor a (64) must match the size of tensor b (96) at non-singleton dimension 1\n",
      "totalscore 0.5574605464935303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (96) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(1.6865e+08)\n",
      "epoch 0 loss 95.14877459467674 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.45', '0.45', '0.42', '0.4']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.45', '0.45', '0.42', '0.4']\n",
      "potential next fragments after thresholding of 0: 4 ['0.45', '0.45', '0.42', '0.4']\n",
      "current depth: 1\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.75', '0.6', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.75', '0.6', '0.59']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.75', '0.6', '0.59']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 4.892515651398103e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.74', '0.73', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.74', '0.73', '0.72']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.74', '0.73', '0.72']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(0.0306)\n",
      "epoch 0 loss 1.5527321428802382e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.82', '0.78', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.82', '0.78', '0.77']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.82', '0.78', '0.77']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(0.0118)\n",
      "epoch 0 loss 1.3096354153703384e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.76', '0.74', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.76', '0.74', '0.73']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.76', '0.74', '0.73']\n",
      "totalscore 0.999999642372174\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net020\n",
      "totalscore 0.7557577477078717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.7557577026611997\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.6372732879806973\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.6183524367809372\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net022\n",
      "totalscore 0.5335504094369397\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.600829854561119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.600829818748869\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net023\n",
      "totalscore 0.7375929981248068\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net024\n",
      "totalscore 0.7341018357033808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7890625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net025\n",
      "totalscore 0.8154790245344232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net026\n",
      "totalscore 0.7841125645368803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net027\n",
      "totalscore 0.772718066521119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:05,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:03<00:03,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net028\n",
      "totalscore 0.7397983980419056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.8', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.8', '0.8']\n",
      "totalscore 0.7397983098510642\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net029\n",
      "totalscore 0.594390529249715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.8']\n",
      "totalscore 0.594390529249715\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7109375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net030\n",
      "totalscore 0.5924922213876893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.7317257247297988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net031\n",
      "totalscore 0.7222301695072346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net032\n",
      "totalscore 0.7517226338386536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(1711428.2500)\n",
      "epoch 0 loss 1.7386338686456486 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(1711428.2500)\n",
      "epoch 0 loss 1.7398428965588004 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.93', '0.7', '0.68', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.93', '0.7', '0.68', '0.68']\n",
      "potential next fragments after thresholding of 0: 4 ['0.93', '0.7', '0.68', '0.68']\n",
      "totalscore 0.6972116829326787\n",
      "diff sampled tensor(53794.6602)\n",
      "epoch 0 loss 1.8429951570471939 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(53794.6602)\n",
      "epoch 0 loss 1.8437554641645781 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.96', '0.76', '0.76', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.96', '0.76', '0.76', '0.75']\n",
      "potential next fragments after thresholding of 0: 4 ['0.96', '0.76', '0.76', '0.75']\n",
      "totalscore 0.672151490683227\n",
      "diff sampled tensor(8233.5762)\n",
      "epoch 0 loss 0.9617592461255132 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(8233.5752)\n",
      "epoch 0 loss 0.9606774583154795 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.99', '0.76', '0.75', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.99', '0.76', '0.75', '0.74']\n",
      "potential next fragments after thresholding of 0: 4 ['0.99', '0.76', '0.75', '0.74']\n",
      "totalscore 0.6634762528195931\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net033\n",
      "totalscore 0.5097576226883439\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5058833764723125\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.5058833463193135\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7265625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5001562804067521\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5301158775240041\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8203125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net037\n",
      "totalscore 0.5272328152975216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net038\n",
      "totalscore 0.5242785658363476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.79']\n",
      "totalscore 0.5242785345869099\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5297490162905554\n",
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.79']\n",
      "totalscore 0.5297490162905554\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 19.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net040\n",
      "totalscore 0.5137594002209447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net041\n",
      "totalscore 0.5112795136524539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net042\n",
      "totalscore 0.5990968942642212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.5893228650093079\n",
      "ERROR The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.91', '0.48', '0.46']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.91', '0.48', '0.46']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.91', '0.48', '0.46']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 4.292004081629861e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.49', '0.43']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.49', '0.43']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.49', '0.43']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(8.1715e-06)\n",
      "epoch 0 loss 5.277181482863278e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.55', '0.55', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.55', '0.5']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.55', '0.5']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(1.6224e-07)\n",
      "epoch 0 loss 3.563195685219807e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.62', '0.49', '0.47']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.62', '0.49', '0.47']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.62', '0.49', '0.47']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(1.2511e-05)\n",
      "epoch 0 loss 3.379058620213625e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.66', '0.63', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.66', '0.6']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.66', '0.6']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(3.1722e-07)\n",
      "epoch 0 loss 5.83530695419161e-11 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.77', '0.71', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.77', '0.71', '0.57']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.77', '0.71', '0.57']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(3.3491e-06)\n",
      "epoch 0 loss 5.189620524698066e-10 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.8', '0.76', '0.65']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.65']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.8', '0.65']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(1.2464e-06)\n",
      "epoch 0 loss 2.166191738455769e-10 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.8', '0.73', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.59']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.59']\n",
      "totalscore 0.9999999999999716\n",
      "diff sampled tensor(0.0018)\n",
      "epoch 0 loss 2.3106616128866244e-07 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.71', '0.67', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.71', '0.67', '0.66']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.71', '0.67', '0.66']\n",
      "totalscore 0.9999999999999716\n",
      "diff sampled tensor(1.1931e-05)\n",
      "epoch 0 loss 8.387619125326693e-10 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.75', '0.74', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.75', '0.74', '0.57']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.75', '0.74', '0.57']\n",
      "totalscore 0.9999999999999716\n",
      "diff sampled tensor(0.0083)\n",
      "epoch 0 loss 2.07759416186992e-06 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.75', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.94', '0.75']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.94', '0.75']\n",
      "totalscore 0.9999999999999716\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.81', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.81']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.81']\n",
      "totalscore 0.9999999999999716\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net043\n",
      "totalscore 0.8076375722884902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.8076375241495396\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net044\n",
      "totalscore 0.6552976750149666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 14\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.84']\n",
      "totalscore 0.6552976750149666\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net045\n",
      "totalscore 0.5476613106851803\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 15\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.97', '0.81', '0.8', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.97', '0.81', '0.8', '0.76']\n",
      "potential next fragments after thresholding of 0: 4 ['0.97', '0.81', '0.8', '0.76']\n",
      "totalscore 0.5313976733501109\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net046\n",
      "totalscore 0.6370532052920371\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net047\n",
      "totalscore 0.9415280818938941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.78125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net048\n",
      "totalscore 0.7500267624854828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.8']\n",
      "totalscore 0.7500268518956403\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net049\n",
      "totalscore 0.6085534726189938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.83', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.83']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.83']\n",
      "totalscore 0.6085534363463803\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.507012389756708\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 14\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.5969883134514519\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net051\n",
      "totalscore 0.7484465241431977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.81', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.81']\n",
      "totalscore 0.7484465241431977\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net052\n",
      "totalscore 0.6097895903588939\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.6045873807360392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.6045874528084714\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net053\n",
      "totalscore 0.7404218912124423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net054\n",
      "totalscore 0.5741201043128804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (96) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "totalscore 0.710065424442271\n",
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 576])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (96) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.82', '0.81']\n",
      "totalscore 0.7100653397958763\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.6953125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net055\n",
      "totalscore 0.5796326519958382\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.5724790582031908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.5724790582031908\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.71875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net056\n",
      "totalscore 0.6739611625671195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net057\n",
      "totalscore 0.6610313653945735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.79']\n",
      "totalscore 0.6610313259940338\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net058\n",
      "totalscore 0.5581995815757194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.5416229609534335\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7109375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5255098205821291\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.5255097892593029\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.6953125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5868338242967172\n",
      "epoch 0 loss 0.0 torch.Size([32, 48]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.82', '0.81']\n",
      "totalscore 0.5868338242967172\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.5546875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net061\n",
      "totalscore 0.8012442825741203\n",
      "ERROR The size of tensor a (120) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "totalscore 0.6538279469218131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (120) must match the size of tensor b (48) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 120]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.82', '0.8']\n",
      "totalscore 0.6538264270456948\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.671875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net062\n",
      "totalscore 0.5342311165302364\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.5248341122026163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.83', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.83', '0.8']\n",
      "totalscore 0.524834174767718\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.65625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net063\n",
      "totalscore 0.7656926475303687\n",
      "ERROR The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n",
      "totalscore 0.7117198796939833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "totalscore 0.572471064932068\n",
      "epoch 0 loss 0.0 torch.Size([32, 40]) torch.Size([32, 576])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.82', '0.81']\n",
      "totalscore 0.5724708943223956\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 20.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.6171875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net064\n",
      "totalscore 0.6559400782727729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (96) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.5995171428877711\n",
      "ERROR The size of tensor a (96) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.6207888578428111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (96) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (96) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (24) must match the size of tensor b (96) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (24) must match the size of tensor b (96) at non-singleton dimension 1\n",
      "totalscore 0.5535861849784851\n",
      "ERROR The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.5011551976203918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.9118267297744751\n",
      "diff sampled tensor(3019890.)\n",
      "epoch 0 loss 0.6917586423912827 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.98', '0.57', '0.53', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.57', '0.5']\n",
      "potential next fragments after thresholding of 0: 3 ['0.98', '0.57', '0.5']\n",
      "totalscore 0.8901187176255547\n",
      "diff sampled tensor(19225.8457)\n",
      "epoch 0 loss 0.48304297242845806 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.97', '0.63', '0.45', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.97', '0.63', '0.45', '0.45']\n",
      "potential next fragments after thresholding of 0: 4 ['0.97', '0.63', '0.45', '0.45']\n",
      "totalscore 0.8626894924012919\n",
      "diff sampled tensor(50328.4062)\n",
      "epoch 0 loss 1.8758441331435223 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.98', '0.66', '0.63', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.63', '0.62']\n",
      "potential next fragments after thresholding of 0: 3 ['0.98', '0.63', '0.62']\n",
      "totalscore 0.8452216048754557\n",
      "diff sampled tensor(2449.8120)\n",
      "epoch 0 loss 0.31154664681882277 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.98', '0.73', '0.72', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.98', '0.73', '0.72', '0.66']\n",
      "potential next fragments after thresholding of 0: 4 ['0.98', '0.73', '0.72', '0.66']\n",
      "totalscore 0.8254422028869639\n",
      "diff sampled tensor(19994.8535)\n",
      "epoch 0 loss 3.0219636255381057 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.97', '0.78', '0.76', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.78', '0.66']\n",
      "potential next fragments after thresholding of 0: 3 ['0.97', '0.78', '0.66']\n",
      "totalscore 0.8035449206425268\n",
      "diff sampled tensor(7176.4429)\n",
      "epoch 0 loss 1.070877503375618 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.98', '0.79', '0.69', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.56']\n",
      "potential next fragments after thresholding of 0: 2 ['0.98', '0.56']\n",
      "totalscore 0.7843065968891145\n",
      "diff sampled tensor(15371.1855)\n",
      "epoch 0 loss 2.3868699754987444 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.99', '0.72', '0.71', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.99', '0.72', '0.71', '0.69']\n",
      "potential next fragments after thresholding of 0: 4 ['0.99', '0.72', '0.71', '0.69']\n",
      "totalscore 0.7754916876564976\n",
      "diff sampled tensor(270.6975)\n",
      "epoch 0 loss 0.07672946307123923 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.99', '0.84', '0.73', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.99', '0.84', '0.73', '0.6']\n",
      "potential next fragments after thresholding of 0: 4 ['0.99', '0.84', '0.73', '0.6']\n",
      "totalscore 0.7659687982222386\n",
      "diff sampled tensor(4507.3906)\n",
      "epoch 0 loss 1.6710504025829083 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.75', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.94', '0.75']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.94', '0.75']\n",
      "totalscore 0.7640162124319401\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.82']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.82']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.82']\n",
      "totalscore 0.7640162124319401\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8203125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net065\n",
      "totalscore 0.623742282877715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.6237423572335895\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net066\n",
      "totalscore 0.5060901353233146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.83', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.83']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.83']\n",
      "totalscore 0.5060901353233146\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net067\n",
      "totalscore 0.7169601641030341\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net068\n",
      "totalscore 0.5768289879026762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.5768289535209893\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7265625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net069\n",
      "totalscore 0.6499027562670491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net070\n",
      "totalscore 0.5655290341947582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.8']\n",
      "totalscore 0.5655289667784438\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7890625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net071\n",
      "totalscore 0.5637770254731674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.94', '0.82', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.82', '0.81']\n",
      "totalscore 0.5637769582657087\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.6953125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net072\n",
      "totalscore 0.5584983458638133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net073\n",
      "totalscore 0.5443628705306145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.5443628380840589\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net074\n",
      "totalscore 0.6460185589983829\n",
      "ERROR The size of tensor a (120) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "totalscore 0.5461950157517181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (120) must match the size of tensor b (48) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 120]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.640625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net075\n",
      "totalscore 0.6171070042427489\n",
      "ERROR The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n",
      "totalscore 0.60871419325307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n",
      "totalscore 0.5542883558383835\n",
      "epoch 0 loss 0.0 torch.Size([32, 40]) torch.Size([32, 576])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (48) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.93', '0.83', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.81']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.83', '0.81']\n",
      "totalscore 0.5542883558383835\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.4765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net076\n",
      "totalscore 0.5469085298078247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (96) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.5349595317407605\n",
      "ERROR The size of tensor a (96) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.5580697679792603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (96) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (96) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (24) must match the size of tensor b (96) at non-singleton dimension 1\n",
      "totalscore 0.518956428325346\n",
      "ERROR The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (24) must match the size of tensor b (96) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (72) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.82', '0.71', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.82', '0.71', '0.63']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.82', '0.71', '0.63']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 5.848227319791016e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 7.964360895558096e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.75', '0.72', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.75', '0.72']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.0149)\n",
      "epoch 0 loss 1.303799524579313e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0149)\n",
      "epoch 0 loss 1.3037756749948744e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.7', '0.69', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.7', '0.69', '0.68']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.7', '0.69', '0.68']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.0381)\n",
      "epoch 0 loss 1.416092600822817e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0381)\n",
      "epoch 0 loss 1.4173729698309123e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.76', '0.76', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.76', '0.76', '0.75']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.76', '0.76', '0.75']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(0.0230)\n",
      "epoch 0 loss 2.7603383962426106e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0230)\n",
      "epoch 0 loss 2.761093276845082e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.77', '0.77', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.77', '0.77', '0.76']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.77', '0.77', '0.76']\n",
      "totalscore 0.999999940395341\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.7705375552177319\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.7705375092901147\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.6251954309699403\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.84']\n",
      "totalscore 0.6251953191762856\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net079\n",
      "totalscore 0.5251247942518806\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.5095301314222853\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net080\n",
      "totalscore 0.6110272203199064\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.7703229188918957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.7551378607749831\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.7551378157652592\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.6360524384355146\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.91', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.6171646121630744\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net083\n",
      "totalscore 0.5325016139858794\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.6003503203124921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.6003503203124921\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net084\n",
      "totalscore 0.7639844732265928\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8359375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net085\n",
      "totalscore 0.7597766828270665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7890625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net086\n",
      "totalscore 0.7536592189859306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.7536591740643406\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.796875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.6115014332971953\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.6115014332971953\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7890625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5132971420551761\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.5944789358146517\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.84375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net089\n",
      "totalscore 0.6951325172343772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.6951325172343772\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net090\n",
      "totalscore 0.5850940462828371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.92', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.84']\n",
      "potential next fragments after thresholding of 0: 2 ['0.97', '0.84']\n",
      "totalscore 0.5677196935437376\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7578125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.5526364534722393\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0: 2 ['1.0', '0.79']\n",
      "totalscore 0.5526364534722393\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.694617473437475\n",
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8046875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net093\n",
      "totalscore 0.6811904527175869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 22.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8125\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net094\n",
      "totalscore 0.7489185929298401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(1711434.1250)\n",
      "epoch 0 loss 2.770333786399997 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.88', '0.73', '0.71', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.88', '0.73', '0.71', '0.69']\n",
      "potential next fragments after thresholding of 0: 4 ['0.88', '0.73', '0.71', '0.69']\n",
      "totalscore 0.6557033327415773\n",
      "diff sampled tensor(56910.0781)\n",
      "epoch 0 loss 16.591993292983698 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.73', '0.72', '0.72', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.73', '0.72', '0.72', '0.71']\n",
      "potential next fragments after thresholding of 0: 4 ['0.73', '0.72', '0.72', '0.71']\n",
      "totalscore 0.5441858930513277\n",
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7734375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net095\n",
      "totalscore 0.528676911366869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.93', '0.81', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.8']\n",
      "totalscore 0.528676785320471\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.75\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net096\n",
      "totalscore 0.5199073513770571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.95', '0.81', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.79']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.79']\n",
      "totalscore 0.5199073203881641\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.7421875\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net097\n",
      "totalscore 0.7201290726661682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.816493570804596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(95752904.)\n",
      "epoch 0 loss 72.49265810908103 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.6', '0.52', '0.49', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.6', '0.52', '0.49', '0.48']\n",
      "potential next fragments after thresholding of 0: 4 ['0.6', '0.52', '0.49', '0.48']\n",
      "totalscore 0.7088370323181152\n",
      "ERROR The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.6333433985710144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(8563424.)\n",
      "epoch 0 loss 101.44842973036694 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.62', '0.58', '0.55', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.62', '0.55', '0.51']\n",
      "potential next fragments after thresholding of 0: 3 ['0.62', '0.55', '0.51']\n",
      "current depth: 1\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.83', '0.64', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 4 ['1.0', '0.83', '0.64', '0.59']\n",
      "potential next fragments after thresholding of 0: 4 ['1.0', '0.83', '0.64', '0.59']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 9.29489415865964e-07 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.83', '0.81', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.72']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.81', '0.72']\n",
      "totalscore 1.0000002384185933\n",
      "diff sampled tensor(0.6827)\n",
      "epoch 0 loss 1.5589182932477082e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.62', '0.54', '0.49']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.62', '0.54']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.62', '0.54']\n",
      "totalscore 1.0000001192092753\n",
      "diff sampled tensor(1.6236)\n",
      "epoch 0 loss 4.015548443346363e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.7', '0.63', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.56']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.7', '0.56']\n",
      "totalscore 1.0000001192092753\n",
      "diff sampled tensor(1.7923)\n",
      "epoch 0 loss 1.777656824724174e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.71', '0.71', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.71', '0.63']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.71', '0.63']\n",
      "totalscore 1.000000238418579\n",
      "diff sampled tensor(3.2916)\n",
      "epoch 0 loss 3.250593734413328e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.71', '0.7', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.63']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.7', '0.63']\n",
      "totalscore 1.000000238418579\n",
      "diff sampled tensor(4.2024)\n",
      "epoch 0 loss 4.281813243305434e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.69', '0.68', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.68', '0.63']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.68', '0.63']\n",
      "totalscore 1.000000238418579\n",
      "diff sampled tensor(2.1107)\n",
      "epoch 0 loss 159.87151121201674 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.77', '0.67', '0.61', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.77', '0.61', '0.55']\n",
      "potential next fragments after thresholding of 0: 3 ['0.77', '0.61', '0.55']\n",
      "totalscore 0.7727123553066662\n",
      "diff sampled tensor(2.8109e+08)\n",
      "epoch 0 loss inf torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['nan', 'nan', 'nan', 'nan']\n",
      "potential next fragments after filter duplicated fragments: 4 ['nan', 'nan', 'nan', 'nan']\n",
      "potential next fragments after thresholding of 0: 0 []\n",
      "totalscore 0.6098349356257415\n",
      "diff sampled tensor(5.5027e+08)\n",
      "epoch 0 loss inf torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['nan', 'nan', 'nan', 'nan']\n",
      "potential next fragments after filter duplicated fragments: 4 ['nan', 'nan', 'nan', 'nan']\n",
      "potential next fragments after thresholding of 0: 0 []\n",
      "totalscore 0.5460410823919659\n",
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['1.0', '0.97', '0.84', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.8']\n",
      "potential next fragments after thresholding of 0: 3 ['1.0', '0.84', '0.8']\n",
      "totalscore 0.5460409522056269\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.765625\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net098\n",
      "totalscore 0.6847184144778851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "totalscore 0.6274208134223613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "totalscore 0.6956288684913403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(2.1757e+08)\n",
      "epoch 0 loss 2727.298977598852 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.74', '0.72', '0.66', '0.64']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.74', '0.66', '0.64']\n",
      "potential next fragments after thresholding of 0: 3 ['0.74', '0.66', '0.64']\n",
      "totalscore 0.5126711706800352\n",
      "diff sampled tensor(96586376.)\n",
      "epoch 0 loss 3067.180155851403 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.7', '0.69', '0.69', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.7', '0.69', '0.69']\n",
      "potential next fragments after thresholding of 0: 3 ['0.7', '0.69', '0.69']\n",
      "totalscore 0.6294743131337555\n",
      "epoch 0 loss 0.0 torch.Size([32, 256]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 1000) (133,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "accuracy 0.8359375\n",
      "saving to _results/1689251079_result_beans_CKA_BS_32_MD_16_T_0_TT_0.5_K_4/net099\n",
      "totalscore 0.7058311350144109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(5.5085e+08)\n",
      "epoch 0 loss 1390.301419005102 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.87', '0.69', '0.68', '0.65']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.87', '0.68', '0.65']\n",
      "potential next fragments after thresholding of 0: 3 ['0.87', '0.68', '0.65']\n",
      "totalscore 0.6165626733218423\n",
      "diff sampled tensor(46118188.)\n",
      "epoch 0 loss 1324.918417171556 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.91', '0.68', '0.65', '0.64']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.91', '0.68', '0.64']\n",
      "potential next fragments after thresholding of 0: 3 ['0.91', '0.68', '0.64']\n",
      "totalscore 0.5636856720806551\n",
      "diff sampled tensor(30143196.)\n",
      "epoch 0 loss 1085.3640161631058 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.92', '0.73', '0.72', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.92', '0.73', '0.72', '0.71']\n",
      "potential next fragments after thresholding of 0: 4 ['0.92', '0.73', '0.72', '0.71']\n",
      "totalscore 0.5193558270557956\n",
      "diff sampled tensor(16559539.)\n",
      "epoch 0 loss 583.1395587531888 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.94', '0.76', '0.74', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.94', '0.76', '0.74', '0.73']\n",
      "potential next fragments after thresholding of 0: 4 ['0.94', '0.76', '0.74', '0.73']\n",
      "totalscore 0.6305031335953454\n",
      "diff sampled tensor(2.1082e+08)\n",
      "epoch 0 loss 3168.3580098054845 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.68', '0.67', '0.62', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.67', '0.62', '0.62']\n",
      "potential next fragments after thresholding of 0: 3 ['0.67', '0.62', '0.62']\n",
      "totalscore 0.6968010898591189\n",
      "ERROR The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.5632936433903586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.6213794640015013\n",
      "diff sampled tensor(1.8769e+08)\n",
      "epoch 0 loss 583.0784687898597 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.73', '0.71', '0.67', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.73', '0.67', '0.55']\n",
      "potential next fragments after thresholding of 0: 3 ['0.73', '0.67', '0.55']\n",
      "totalscore 0.5371676772040322\n",
      "ERROR The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.8096709620560247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (128) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(20370450.)\n",
      "epoch 0 loss 1.2105595542460073 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(20370454.)\n",
      "epoch 0 loss 1.2106235878808158 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.71', '0.65', '0.62', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.71', '0.62', '0.57']\n",
      "potential next fragments after thresholding of 0: 3 ['0.71', '0.62', '0.57']\n",
      "totalscore 0.5711902935343595\n",
      "diff sampled tensor(509975.3750)\n",
      "epoch 0 loss 3.073505216715287 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(509975.4375)\n",
      "epoch 0 loss 3.073537663537629 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.63', '0.63', '0.62', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 4 ['0.63', '0.63', '0.62', '0.61']\n",
      "potential next fragments after thresholding of 0: 4 ['0.63', '0.63', '0.62', '0.61']\n",
      "totalscore 0.5028884752909453\n",
      "ERROR The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n",
      "totalscore 0.7157940525762996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (256) must match the size of tensor b (64) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n",
      "totalscore 0.8316447138786316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff sampled tensor(1.0251e+08)\n",
      "epoch 0 loss 46.96131874590504 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.7', '0.56', '0.55', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.7', '0.56', '0.5']\n",
      "potential next fragments after thresholding of 0: 3 ['0.7', '0.56', '0.5']\n",
      "totalscore 0.581516745667976\n",
      "diff sampled tensor(68836120.)\n",
      "epoch 0 loss 132.4034359601079 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.71', '0.71', '0.53', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.71', '0.53']\n",
      "potential next fragments after thresholding of 0: 2 ['0.71', '0.53']\n",
      "totalscore 0.6421898007392883\n",
      "diff sampled tensor(3019062.7500)\n",
      "epoch 0 loss 1.8139722517558508 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(3019062.5000)\n",
      "epoch 0 loss 1.8139731470419436 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 4\n",
      "potential next fragments before thresholding of 0: 4 ['0.74', '0.7', '0.68', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.74', '0.68', '0.63']\n",
      "potential next fragments after thresholding of 0: 3 ['0.74', '0.68', '0.63']\n",
      "totalscore 0.5942959785461426\n",
      "ERROR The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (64) must match the size of tensor b (256) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from stitchnet.stitchonnx.report import Report, ReportPlants, ReportKNNHFDataset\n",
    "import traceback\n",
    "scoreMapper = ScoreMapper(nets, data_score, scoring_method='CKA')\n",
    "with ReportKNNHFDataset(EVAL_BATCH_SIZE, f'./_results/{RESULT_NAME}.txt', 'a', label='labels') as report:\n",
    "    # for _ in tqdm(range(50)):\n",
    "    generator = generate_networks(nets, scoreMapper, data_score, \n",
    "                          threshold=THRESOULD, totalThreshold=TOTAL_THRESOULD, \n",
    "                          maxDepth=MAX_DEPTH, sample=False, K=K)\n",
    "    for i,(s,net) in enumerate(generator):\n",
    "        try:\n",
    "            netname = f\"_results/{RESULT_NAME}/net{k:03}\"\n",
    "            report.evaluate(nets, net, netname, s, dataset_val, dataset_train)\n",
    "            net.save(netname)\n",
    "            k += 1\n",
    "        except Exception as e:\n",
    "            print('ERROR', e)\n",
    "            traceback.print_exc()\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5d2633-6432-443e-b881-de99afb22330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stitchnet.stitchonnx.utils import accuracy_score_net_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f126de0f-ac3c-4e9e-911e-5c315a1cce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,t in dataset_val:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a392215-d1e5-400e-9722-6043a8075896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bdcdb0-9b81-415e-9c1d-167a511a14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score_net_plants(net, dataset_val, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5f2ee5b-79e7-4031-8da9-370ba69998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# knn.fit(np.ones([100,10]), np.ones([100,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71a77cd2-0240-4b22-b0c5-748156f96db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = knn.predict(np.ones([1,10]))\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0e38c8-add9-4b3d-8fe1-726c3c2b20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0062065-28d9-4d1d-84c8-e337735b9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ca02b-b974-4eea-be3d-c7c40ac4148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e1ce2-30c1-4741-be84-b9de165be464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stitchnet",
   "language": "python",
   "name": "stitchnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
