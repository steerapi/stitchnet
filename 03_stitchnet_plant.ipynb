{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02463b7-9fb2-4fc9-b3d4-963da1093a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c962933-5851-48ea-9250-a139b0408baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46146e10-04f2-4fa4-a001-24fdf1398844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skl2onnx.helpers.onnx_helper import load_onnx_model\n",
    "from stitchnet.stitchonnx.utils import Net\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "netsFiles = sorted(glob('_models/fragments/net*'))\n",
    "nets = []\n",
    "for i,netsFile in enumerate(netsFiles):\n",
    "    fragmentFiles = sorted(glob(str(Path(netsFile)/'fragment*.onnx')))\n",
    "    onnxFragments = []\n",
    "    for fragmentFile in fragmentFiles:\n",
    "        onnxFragment = load_onnx_model(fragmentFile)\n",
    "        onnxFragments.append(onnxFragment)\n",
    "    net1 = Net(onnxFragments, i)\n",
    "    nets.append(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd9e874-d12e-4744-8c34-f3ca6aa5e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.ones(1,2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991aecb8-aee4-4bc0-a464-0b308014566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration sampath017--plants-b46ce6bc289739b0\n",
      "Found cached dataset imagefolder (/home/jupyter-steerapi/.cache/huggingface/datasets/sampath017___imagefolder/sampath017--plants-b46ce6bc289739b0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068db1758a144088a1162d2895374490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/sampath017___imagefolder/sampath017--plants-b46ce6bc289739b0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-42a0da81642841ef.arrow and /home/jupyter-steerapi/.cache/huggingface/datasets/sampath017___imagefolder/sampath017--plants-b46ce6bc289739b0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-ff7aeed0fe4ad290.arrow\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/sampath017___imagefolder/sampath017--plants-b46ce6bc289739b0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-0c31efc05ee7bb41.arrow\n",
      "Loading cached processed dataset at /home/jupyter-steerapi/.cache/huggingface/datasets/sampath017___imagefolder/sampath017--plants-b46ce6bc289739b0/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f/cache-1a332b8b2ccf86ac.arrow\n"
     ]
    }
   ],
   "source": [
    "from stitchnet.stitchonnx.utils import load_cats_and_dogs_dset,convert_imagenet_to_cat_dog_label\n",
    "from stitchnet.stitchonnx.utils import accuracy_score_model,accuracy_score_net,load_dl\n",
    "from stitchnet.stitchonnx.utils import generate_networks, ScoreMapper\n",
    "from stitchnet.stitchonnx.report import Report\n",
    "from stitchnet.stitchonnx.utils import evalulate_stitchnet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "random.seed(51)\n",
    "np.random.seed(24)\n",
    "torch.manual_seed(77)\n",
    "\n",
    "K = 2\n",
    "STITCH_BATCH_SIZE = 32 # todo study the effect\n",
    "MAX_DEPTH = 16\n",
    "THRESOULD = 0.9\n",
    "TOTAL_THRESOULD = 0.9\n",
    "\n",
    "RESULT_NAME = f\"{int(time.time())}_result_plant_CKA_BS_{STITCH_BATCH_SIZE}_MD_{MAX_DEPTH}_T_{THRESOULD}_TT_{TOTAL_THRESOULD}_K_{K}\"\n",
    "\n",
    "EVAL_BATCH_SIZE = 64\n",
    "\n",
    "from stitchnet.stitchonnx.utils import load_hf_train_val_dset\n",
    "\n",
    "dataset_train, dataset_val = load_hf_train_val_dset('sampath017/plants')\n",
    "\n",
    "dl_score = load_dl(dataset_train, STITCH_BATCH_SIZE)\n",
    "data_score,t = next(iter(dl_score))\n",
    "data_score = data_score.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5e71f2-1d9c-416f-b0ab-b90f1ebc76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(1)\n",
    "k = 0\n",
    "if os.path.exists(f'./_results/{RESULT_NAME}.txt'):\n",
    "    with open(f'./_results/{RESULT_NAME}.txt', 'r') as f:\n",
    "        k = len(f.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef687c5-6b30-4c10-8536-e0eb218da7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth: 1\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.988104149081499e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0026)\n",
      "epoch 0 loss 2.2259588989142614e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.0718)\n",
      "epoch 0 loss 9.68740077843592e-06 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999997019767974\n",
      "diff sampled tensor(0.1415)\n",
      "epoch 0 loss 2.165955144184581e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "current depth: 5\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.93']\n",
      "totalscore 0.9999997019767974\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "current depth: 6\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9999997019767974\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 7\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9999997019767974\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9318181818181818\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net000\n",
      "totalscore 0.981082862292801\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 8\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.981082979246992\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9545454545454546\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net001\n",
      "totalscore 0.9625226415200757\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 9\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9625226415200757\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9318181818181818\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net002\n",
      "totalscore 0.9443148069626696\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 10\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9443148069626696\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9090909090909091\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net003\n",
      "totalscore 0.9264503929700814\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 11\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9264503929700814\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9090909090909091\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net004\n",
      "totalscore 0.9089243772013604\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "current depth: 12\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.98']\n",
      "totalscore 0.9089243772013604\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9090909090909091\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net005\n",
      "totalscore 0.981083100711309\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9090909090909091\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net006\n",
      "totalscore 0.9347267941454035\n",
      "ERROR unsupport linear to conv stitching\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1083, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 723, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 631, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 5.953647700974072e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0265)\n",
      "epoch 0 loss 8.590836192265019e-07 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.999999880790714\n",
      "diff sampled tensor(0.0130)\n",
      "epoch 0 loss 1.3846135831898915e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999998211860763\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net007\n",
      "current depth: 1\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.94']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 7.068332038535015e-13 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.92']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(1.5055e-06)\n",
      "epoch 0 loss 5.314258891573173e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(2.0026e-07)\n",
      "epoch 0 loss 5.1500563875841953e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(1.3598e-05)\n",
      "epoch 0 loss 4.345602993096201e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "current depth: 5\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(4.5108e-07)\n",
      "epoch 0 loss 1.0853301024344917e-10 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "current depth: 6\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(4.9691e-06)\n",
      "epoch 0 loss 6.821029546177688e-10 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "current depth: 7\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000000596046235\n",
      "diff sampled tensor(1.5730e-06)\n",
      "epoch 0 loss 2.527832773034672e-10 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "current depth: 8\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001788139201\n",
      "diff sampled tensor(3.4411e-06)\n",
      "epoch 0 loss 5.496264758512692e-10 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "current depth: 9\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.000000298023231\n",
      "diff sampled tensor(5.7814e-05)\n",
      "epoch 0 loss 1.284896296390204e-08 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "current depth: 10\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.92']\n",
      "totalscore 1.000000417232556\n",
      "diff sampled tensor(0.0009)\n",
      "epoch 0 loss 2.2192157024508151e-07 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "current depth: 11\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.95']\n",
      "totalscore 1.0000003576278864\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "current depth: 12\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.95']\n",
      "totalscore 1.0000003576278864\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net008\n",
      "totalscore 0.9516997164604986\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "current depth: 13\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.95']\n",
      "totalscore 0.9516997164604986\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net009\n",
      "totalscore 0.9023132804901083\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "current depth: 14\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.94']\n",
      "totalscore 0.9023134956183585\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net010\n",
      "totalscore 0.9499708801385204\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9545454545454546\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net011\n",
      "totalscore 0.9170654764965848\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "current depth: 11\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.95']\n",
      "totalscore 0.9170654764965848\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9545454545454546\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net012\n",
      "totalscore 0.9157995481252001\n",
      "diff sampled tensor(2982464.)\n",
      "epoch 0 loss 3.7067519547987957 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 0 []\n",
      "totalscore 0.937415361404419\n",
      "diff sampled tensor(2982463.)\n",
      "epoch 0 loss 0.6012409870721855 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['0.99']\n",
      "totalscore 0.9235945156731873\n",
      "diff sampled tensor(16427.6953)\n",
      "epoch 0 loss 0.426459082535335 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['0.98']\n",
      "totalscore 0.9026357906488409\n",
      "diff sampled tensor(60034.4219)\n",
      "epoch 0 loss 2.097846065248762 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['0.98']\n",
      "current depth: 1\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.421065396872677e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.392522256798955e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0166)\n",
      "epoch 0 loss 1.492474407824579e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0166)\n",
      "epoch 0 loss 1.492452990036401e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.999999880790714\n",
      "diff sampled tensor(0.0368)\n",
      "epoch 0 loss 1.3123620758459747e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0368)\n",
      "epoch 0 loss 1.3119568913160556e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 0.9999997615814387\n",
      "diff sampled tensor(0.0222)\n",
      "epoch 0 loss 2.7304315005253278e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0222)\n",
      "epoch 0 loss 2.730094801874508e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "current depth: 5\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 2 ['1.0', '0.91']\n",
      "totalscore 0.9999997615814387\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9545454545454546\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net013\n",
      "totalscore 0.9109280917815588\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 1000) (175,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "saving to _results/1689063880_result_plant_CKA_BS_32_MD_16_T_0.9_TT_0.9_K_2/net014\n",
      "current depth: 1\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.178479648705879e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "current depth: 2\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.9110)\n",
      "epoch 0 loss 2.1059806472317643e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "current depth: 3\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(2.2831)\n",
      "epoch 0 loss 5.544479561148346e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "current depth: 4\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(2.4594)\n",
      "epoch 0 loss 2.4275476139986756e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "current depth: 5\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(4.7621)\n",
      "epoch 0 loss 4.694000500069019e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "current depth: 6\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(6.4272)\n",
      "epoch 0 loss 6.533137757844311e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "current depth: 7\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(3.3265)\n",
      "epoch 0 loss 13880949.920831563 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "current depth: 8\n",
      "potential next fragments: 2\n",
      "potential next fragments after thresholding of 0.9: 0 []\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from stitchnet.stitchonnx.report import Report, ReportPlants\n",
    "\n",
    "scoreMapper = ScoreMapper(nets, data_score, scoring_method='CKA')\n",
    "with ReportPlants(EVAL_BATCH_SIZE, f'./_results/{RESULT_NAME}.txt', 'a') as report:\n",
    "    # for _ in tqdm(range(50)):\n",
    "    generator = generate_networks(nets, scoreMapper, data_score, \n",
    "                          threshold=THRESOULD, totalThreshold=TOTAL_THRESOULD, \n",
    "                          maxDepth=MAX_DEPTH, sample=False, K=K)\n",
    "    for i,(s,net) in enumerate(generator):\n",
    "        try:\n",
    "            netname = f\"_results/{RESULT_NAME}/net{k:03}\"\n",
    "            report.evaluate(nets, net, netname, s, dataset_val, dataset_train)\n",
    "            net.save(netname)\n",
    "            k += 1\n",
    "        except Exception as e:\n",
    "            print('ERROR', e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5d2633-6432-443e-b881-de99afb22330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stitchnet.stitchonnx.utils import accuracy_score_net_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f126de0f-ac3c-4e9e-911e-5c315a1cce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,t in dataset_val:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a392215-d1e5-400e-9722-6043a8075896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bdcdb0-9b81-415e-9c1d-167a511a14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score_net_plants(net, dataset_val, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f2ee5b-79e7-4031-8da9-370ba69998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# knn.fit(np.ones([100,10]), np.ones([100,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a77cd2-0240-4b22-b0c5-748156f96db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = knn.predict(np.ones([1,10]))\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f0e38c8-add9-4b3d-8fe1-726c3c2b20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0062065-28d9-4d1d-84c8-e337735b9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ca02b-b974-4eea-be3d-c7c40ac4148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e1ce2-30c1-4741-be84-b9de165be464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stitchnet",
   "language": "python",
   "name": "stitchnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
