{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02463b7-9fb2-4fc9-b3d4-963da1093a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46146e10-04f2-4fa4-a001-24fdf1398844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skl2onnx.helpers.onnx_helper import load_onnx_model\n",
    "from stitchnet.stitchonnx.utils import Net\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "netsFiles = sorted(glob('_models/fragments/net*'))\n",
    "nets = []\n",
    "for i,netsFile in enumerate(netsFiles):\n",
    "    fragmentFiles = sorted(glob(str(Path(netsFile)/'fragment*.onnx')))\n",
    "    onnxFragments = []\n",
    "    for fragmentFile in fragmentFiles:\n",
    "        onnxFragment = load_onnx_model(fragmentFile)\n",
    "        onnxFragments.append(onnxFragment)\n",
    "    net1 = Net(onnxFragments, i)\n",
    "    nets.append(net1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991aecb8-aee4-4bc0-a464-0b308014566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stitchnet.stitchonnx.utils import load_cats_and_dogs_dset,convert_imagenet_to_cat_dog_label\n",
    "from stitchnet.stitchonnx.utils import accuracy_score_model,accuracy_score_net,load_dl\n",
    "from stitchnet.stitchonnx.utils import generate_networks, ScoreMapper\n",
    "from stitchnet.stitchonnx.report import Report\n",
    "from stitchnet.stitchonnx.utils import evalulate_stitchnet\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "random.seed(51)\n",
    "np.random.seed(24)\n",
    "torch.manual_seed(77)\n",
    "\n",
    "K = 3\n",
    "STITCH_BATCH_SIZE = 32 # todo study the effect\n",
    "MAX_DEPTH = 16\n",
    "THRESOULD = 0.8\n",
    "TOTAL_THRESOULD = 0.8\n",
    "EVAL_BATCH_SIZE = 16\n",
    "EXP_TIME = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb2ee26-1adf-4d93-8afc-bc6c1cda9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_train\n",
    "# dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a886cf0-f143-4464-8406-c8331a0cd32d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.6', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.6', '0.59']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 6.969868395283225e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.59', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.59', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0019)\n",
      "epoch 0 loss 1.5265403865900623e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.77', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.77', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.0653)\n",
      "epoch 0 loss 8.780113145841297e-06 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.78']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.79', '0.78']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.1522)\n",
      "epoch 0 loss 2.2931528324536847e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.95']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.95']\n",
      "totalscore 1.0000001192092896\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.97', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.97']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.97']\n",
      "totalscore 1.0000001192092896\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.97', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 74.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n",
      "accuracy 0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net000\n",
      "totalscore 0.9706867302282589\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 69.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n",
      "accuracy 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net001\n",
      "totalscore 0.9532236401109131\n",
      "ERROR unsupport linear to conv stitching\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.1443427207808682e-10 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(0.0282)\n",
      "epoch 0 loss 9.674719125059152e-07 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.83', '0.83']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.83']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.83', '0.83']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(0.0100)\n",
      "epoch 0 loss 1.0886742344080964e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.88', '0.86']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.88', '0.86']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.88', '0.86']\n",
      "totalscore 0.9999999999999858\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6153846153846154\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net002\n",
      "totalscore 0.8761202096938963\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6923076923076923\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net003\n",
      "totalscore 0.863120377063739\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7692307692307693\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net004\n",
      "totalscore 0.831335246562946\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6538461538461539\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net005\n",
      "totalscore 0.8292643427848698\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6923076923076923\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net006\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.89', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.89', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.89']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.4951368112464201e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.59']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185933\n",
      "diff sampled tensor(2.8938e-06)\n",
      "epoch 0 loss 5.119037107646179e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.57', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.57', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(1.7424e-07)\n",
      "epoch 0 loss 4.283669861570458e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.6', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.6', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(1.1907e-05)\n",
      "epoch 0 loss 3.839185398162621e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.66', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.66', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(3.7857e-07)\n",
      "epoch 0 loss 8.343659550117694e-11 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.79', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002980232452\n",
      "diff sampled tensor(4.3825e-06)\n",
      "epoch 0 loss 6.158572246277447e-10 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002980232452\n",
      "diff sampled tensor(1.3695e-06)\n",
      "epoch 0 loss 2.2842324403853228e-10 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139201\n",
      "diff sampled tensor(3.1424e-06)\n",
      "epoch 0 loss 4.894319144977071e-10 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.76', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.76', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403952984\n",
      "diff sampled tensor(5.0078e-08)\n",
      "epoch 0 loss 2.6374691546406518e-11 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.9999998807906572\n",
      "diff sampled tensor(0.0040)\n",
      "epoch 0 loss 1.130767264023271e-06 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.82']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.94', '0.82']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.94', '0.82']\n",
      "totalscore 0.9999998807906572\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999325\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6538461538461539\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net007\n",
      "totalscore 0.9409941505200048\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6538461538461539\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.8154806118630084\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8461538461538461\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net009\n",
      "totalscore 0.8739235476300459\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8739234955401433\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6923076923076923\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net010\n",
      "totalscore 0.8930677175521851\n",
      "diff sampled tensor(2847356.5000)\n",
      "epoch 0 loss 0.6394626005571715 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.57', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.8758398821764146\n",
      "diff sampled tensor(18774.7266)\n",
      "epoch 0 loss 0.47199332470796546 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.57', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.57', '0.51']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8466443076051497\n",
      "diff sampled tensor(68280.5547)\n",
      "epoch 0 loss 2.4065446075128047 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.64', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.64']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.8335065272343227\n",
      "diff sampled tensor(4030.8928)\n",
      "epoch 0 loss 0.42470139386702555 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.78', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.78', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8091181928277484\n",
      "diff sampled tensor(27929.0625)\n",
      "epoch 0 loss 4.1537445224061305 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.78', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 9.870918410879352e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.4573744153089074e-10 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.71', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.71', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0361)\n",
      "epoch 0 loss 2.6427973786704403e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0361)\n",
      "epoch 0 loss 2.642839094779465e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.65', '0.65']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.65', '0.65']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0439)\n",
      "epoch 0 loss 1.571058674573801e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0439)\n",
      "epoch 0 loss 1.5706733782800647e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.86', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.86', '0.84']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.86', '0.84']\n",
      "totalscore 0.9999998211860728\n",
      "diff sampled tensor(0.0245)\n",
      "epoch 0 loss 2.9307592164829602e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0245)\n",
      "epoch 0 loss 2.9311557561729332e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.87', '0.85']\n",
      "totalscore 0.9999997019768045\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7692307692307693\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net011\n",
      "totalscore 0.8713209263108288\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 14.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n",
      "accuracy 0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net012\n",
      "totalscore 0.8457094706816217\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7307692307692307\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net013\n",
      "totalscore 0.8564384069181408\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n",
      "accuracy 0.6153846153846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net014\n",
      "totalscore 0.8374413348769316\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.97', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.8374413348769316\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n",
      "accuracy 0.6538461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net015\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.63', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.63', '0.45']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.341142236903036e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.67']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(1.0691)\n",
      "epoch 0 loss 2.3803337897761036e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.64']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(2.7207)\n",
      "epoch 0 loss 6.600259904625629e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(2.9508)\n",
      "epoch 0 loss 2.91002795852457e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(5.8539)\n",
      "epoch 0 loss 5.768640407115193e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.71']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(8.2043)\n",
      "epoch 0 loss 8.319437731596717e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.71', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(4.1945)\n",
      "epoch 0 loss 0.0008736804896271882 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.72', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.72', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999985694885147\n",
      "diff sampled tensor(527.6310)\n",
      "epoch 0 loss 0.008301587205152122 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.75', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.75', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999982714657172\n",
      "diff sampled tensor(72.2019)\n",
      "epoch 0 loss 0.0026421304602099924 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.77', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.77', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999980926520919\n",
      "diff sampled tensor(10.3288)\n",
      "epoch 0 loss 0.0013854470180005444 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.79', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999979734430298\n",
      "diff sampled tensor(4.9749)\n",
      "epoch 0 loss 0.0006490080446308972 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.81', '0.78']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.78']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.81']\n",
      "totalscore 0.9999979734430298\n",
      "diff sampled tensor(2.4526)\n",
      "epoch 0 loss 0.00031072441108372746 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.98', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999979734430298\n",
      "epoch 0 loss 0.0 torch.Size([32, 25088]) torch.Size([32, 25088])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 14\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999979138385058\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 15\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.84', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.84']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.84', '0.84']\n",
      "totalscore 0.9999977946294649\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5769230769230769\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net016\n",
      "totalscore 0.8420375900648845\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7307692307692307\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net017\n",
      "totalscore 0.8399985790254785\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6538461538461539\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net018\n",
      "totalscore 0.9613140413327046\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5384615384615384\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net019\n",
      "totalscore 0.8085958068191869\n",
      "epoch 0 loss 0.0 torch.Size([32, 512]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8085958068191869\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000) (319,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6923076923076923\n",
      "saving to _results/1689275240_result_food101/set0_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.55', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.55', '0.55']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.233846008606562e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.54', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.54', '0.5']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.0110)\n",
      "epoch 0 loss 5.29066296056679e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.1082)\n",
      "epoch 0 loss 1.3881622670361629e-05 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.2001)\n",
      "epoch 0 loss 3.0381607095650314e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999997615814351\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.93']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999998807906962\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.9999998807906962\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5909090909090909\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.8772094992149224\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.84']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.84']\n",
      "totalscore 0.8772094992149224\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 74.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.9640825476449203\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 76.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.9562561564139997\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 25088])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.95']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.95']\n",
      "totalscore 0.9562561564139997\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.85']\n",
      "totalscore 0.9562561564139997\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 70.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.45454545454545453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net003\n",
      "totalscore 0.8085539580925668\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 75.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.45454545454545453\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.9094024879015677\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 77.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.328667574203023e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0014)\n",
      "epoch 0 loss 4.803124595559429e-08 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.83', '0.82']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.82']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.83', '0.82']\n",
      "totalscore 0.999999880790714\n",
      "diff sampled tensor(0.0034)\n",
      "epoch 0 loss 3.294679637682358e-07 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.87', '0.87']\n",
      "totalscore 0.999999880790714\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5909090909090909\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net006\n",
      "totalscore 0.8744753152757414\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5454545454545454\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net007\n",
      "totalscore 0.8661158840518044\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5909090909090909\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net008\n",
      "totalscore 0.829110632591803\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5909090909090909\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net009\n",
      "totalscore 0.8224979148806355\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6818181818181818\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net010\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.94', '0.54']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.94']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.1230393209770128e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.46']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.46']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(2.1437e-06)\n",
      "epoch 0 loss 5.605651412867321e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.61', '0.53']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.53']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(1.8091e-07)\n",
      "epoch 0 loss 6.597401479999382e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.59', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.59', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(2.6509e-05)\n",
      "epoch 0 loss 7.41724482287335e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.65', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.65']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(7.6011e-07)\n",
      "epoch 0 loss 1.4345764259055775e-10 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.8']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(0.0034)\n",
      "epoch 0 loss 4.0144700784478527e-07 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.78']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.78']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(0.0006)\n",
      "epoch 0 loss 8.995462334199573e-08 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(0.0005)\n",
      "epoch 0 loss 4.003233561424891e-08 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.76', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.76', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(6.4187e-06)\n",
      "epoch 0 loss 1.4264603647944216e-09 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.89', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.89', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.89']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(0.0121)\n",
      "epoch 0 loss 2.9675845455910477e-06 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.93', '0.81']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.93', '0.81']\n",
      "totalscore 0.9999997615814209\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.9999997019767903\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5454545454545454\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net011\n",
      "totalscore 0.874472171193986\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6818181818181818\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net012\n",
      "totalscore 0.933169074872816\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.45454545454545453\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net013\n",
      "totalscore 0.8097147572380363\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.8097147572380363\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6818181818181818\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net014\n",
      "totalscore 0.8914638291044186\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8914637228336488\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6818181818181818\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net015\n",
      "totalscore 0.8015457268843961\n",
      "ERROR The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n",
      "totalscore 0.9429342150688171\n",
      "diff sampled tensor(2829225.5000)\n",
      "epoch 0 loss 0.6420140905039651 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.54', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.54']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.9245831203839323\n",
      "diff sampled tensor(18720.0312)\n",
      "epoch 0 loss 0.4633555497441973 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.61', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.61', '0.51']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8970170987190956\n",
      "diff sampled tensor(67218.3984)\n",
      "epoch 0 loss 2.37694112622008 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.64', '0.58']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.64', '0.58']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.881023110686282\n",
      "diff sampled tensor(3848.5901)\n",
      "epoch 0 loss 0.42469737967666316 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.77', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.77', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8543369664885996\n",
      "diff sampled tensor(27303.7656)\n",
      "epoch 0 loss 4.0776568821498325 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.78', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8278493478550406\n",
      "diff sampled tensor(9527.5527)\n",
      "epoch 0 loss 1.4142764733762156 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.75', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 1 ['0.97']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8036213116365815\n",
      "diff sampled tensor(19679.9707)\n",
      "epoch 0 loss 3.0518168624566524 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.77', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.77', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.371474014284954e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.115843130760369e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998211860657\n",
      "diff sampled tensor(0.0173)\n",
      "epoch 0 loss 1.6064145003782665e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0173)\n",
      "epoch 0 loss 1.6064293971242349e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.67', '0.63']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.67', '0.63']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997615814316\n",
      "diff sampled tensor(0.0529)\n",
      "epoch 0 loss 1.7691141340260308e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0529)\n",
      "epoch 0 loss 1.7704671976463608e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.84', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.84', '0.84']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.84', '0.84']\n",
      "totalscore 0.9999995827675399\n",
      "diff sampled tensor(0.0243)\n",
      "epoch 0 loss 2.9880511461595567e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0243)\n",
      "epoch 0 loss 2.9859858507418776e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.86']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.86']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.87', '0.86']\n",
      "totalscore 0.9999994635583\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net016\n",
      "totalscore 0.8661546669552074\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5909090909090909\n",
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net017\n",
      "totalscore 0.8631424282789977\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net018\n",
      "totalscore 0.83554581748343\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.83554581748343\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5909090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net019\n",
      "totalscore 0.8351318037195288\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 1000) (306,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 3, 224, 224)\n",
      "accuracy 0.5909090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689275838_result_food101/set1_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net020\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.42']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.42']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.2297247301721167e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.66', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.66']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.9636)\n",
      "epoch 0 loss 2.1484191212637744e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.64']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(2.4539)\n",
      "epoch 0 loss 5.947087433413595e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(2.6711)\n",
      "epoch 0 loss 2.6362160237372984e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(5.2403)\n",
      "epoch 0 loss 5.217894067754969e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.72', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(7.4894)\n",
      "epoch 0 loss 7.631506957054348e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906998\n",
      "diff sampled tensor(3.9621)\n",
      "epoch 0 loss 417305.69892665104 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.5', '0.46', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.5', '0.46']\n",
      "potential next fragments after thresholding of 0.8: 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 27, 27)\n",
      "(32, 192, 13, 13)\n",
      "(32, 384, 13, 13)\n",
      "(32, 256, 13, 13)\n",
      "(32, 9216)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "current depth: 1\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 16, 56, 56)(32, 3, 224, 224)\n",
      "\n",
      "(32, 64, 56, 56)\n",
      "(32, 16, 56, 56)(32, 64, 224, 224)\n",
      "\n",
      "(32, 256, 56, 56)\n",
      "(32, 256, 56, 56)\n",
      "(32, 72, 28, 28)\n",
      "(32, 64, 112, 112)(32, 24, 28, 28)\n",
      "\n",
      "(32, 96, 14, 14)(32, 512, 28, 28)\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 128, 112, 112)\n",
      "(32, 128, 56, 56)(32, 40, 14, 14)\n",
      "\n",
      "(32, 1024, 14, 14)\n",
      "(32, 120, 14, 14)\n",
      "(32, 1024, 14, 14)(32, 256, 56, 56)\n",
      "(32, 2048)\n",
      "(32, 48, 14, 14)\n",
      "\n",
      "(32, 288, 7, 7)\n",
      "(32, 256, 56, 56)\n",
      "(32, 1024)\n",
      "(32, 256, 28, 28)\n",
      "(32, 96, 7, 7)\n",
      "(32, 512, 28, 28)(32, 576)\n",
      "\n",
      "(32, 1024)\n",
      "(32, 512, 28, 28)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 25088)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.62', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.62', '0.56']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.632856874107141e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.64', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.64', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0079)\n",
      "epoch 0 loss 4.933946868425411e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.78']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.79', '0.78']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.1217)\n",
      "epoch 0 loss 1.6072186015921055e-05 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.2380)\n",
      "epoch 0 loss 3.618219062774139e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.96', '0.95']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.96', '0.95']\n",
      "totalscore 0.9999999403953552\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.93']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999999403953552\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.89']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.89']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.89']\n",
      "totalscore 0.9999999403953552\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 81.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.7931034482758621\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.8946896258181525\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.9']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.9']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.9']\n",
      "totalscore 0.8946896258181525\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 82.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.8620689655172413\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalscore 0.8050733509157257\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 83.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.8275862068965517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net002\n",
      "totalscore 0.9638480565638474\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 83.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.8275862068965517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net003\n",
      "totalscore 0.9552174833287275\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.954315843920952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR unsupport linear to conv stitching\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 7.146239644540997e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.77']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0002)\n",
      "epoch 0 loss 1.0472631378879484e-08 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.85', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.85', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.85', '0.85']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0047)\n",
      "epoch 0 loss 4.575569145883343e-07 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.93', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.93', '0.91']\n",
      "totalscore 1.0\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net004\n",
      "totalscore 0.9320348501205444\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9655172413793104\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net005\n",
      "totalscore 0.9104574918746948\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net006\n",
      "totalscore 0.8530334830284119\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net007\n",
      "totalscore 0.8457126617431641\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net008\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.96', '0.51']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.913015497984477e-13 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(2.1108e-06)\n",
      "epoch 0 loss 5.520149680684868e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.56', '0.52']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.56']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(1.9809e-07)\n",
      "epoch 0 loss 4.379738918475094e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.62', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.62', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(1.4744e-05)\n",
      "epoch 0 loss 4.3925023142575373e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.66', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.66', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(4.3362e-07)\n",
      "epoch 0 loss 9.207586394013584e-11 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.8']\n",
      "totalscore 1.000000119209279\n",
      "diff sampled tensor(0.0036)\n",
      "epoch 0 loss 4.312794734854536e-07 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.78']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185827\n",
      "diff sampled tensor(0.0008)\n",
      "epoch 0 loss 1.0350489024598833e-07 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185827\n",
      "diff sampled tensor(0.0012)\n",
      "epoch 0 loss 1.8147289312987504e-07 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.77', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.77', '0.71']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185827\n",
      "diff sampled tensor(3.4085e-05)\n",
      "epoch 0 loss 9.313239666992057e-09 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.85', '0.79']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.85', '0.79']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.85']\n",
      "totalscore 1.0000002384185827\n",
      "diff sampled tensor(0.0006)\n",
      "epoch 0 loss 2.3139174879119942e-07 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.93', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.93', '0.85']\n",
      "totalscore 1.0000002384185827\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.91']\n",
      "totalscore 1.0000002384185827\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.896551724137931\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net009\n",
      "totalscore 0.9104543710837764\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8275862068965517\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net010\n",
      "totalscore 0.9337550839793385\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.896551724137931\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net011\n",
      "totalscore 0.8504191876456731\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8275862068965517\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net012\n",
      "totalscore 0.8490537045129573\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.91']\n",
      "totalscore 0.8490536539054128\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net013\n",
      "totalscore 0.8025274519671157\n",
      "ERROR The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n",
      "totalscore 0.9573230743408203\n",
      "diff sampled tensor(2959978.)\n",
      "epoch 0 loss 0.7213833240830169 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.57', '0.5']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.57', '0.5']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.9393220145949499\n",
      "diff sampled tensor(21529.9258)\n",
      "epoch 0 loss 0.5301662002290998 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.57', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.57', '0.51']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.9080214444552177\n",
      "diff sampled tensor(75783.3984)\n",
      "epoch 0 loss 2.636215608947131 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.6', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.59']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.8889203332646389\n",
      "diff sampled tensor(4405.0449)\n",
      "epoch 0 loss 0.4885744415983862 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.76', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.76', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8578677050407981\n",
      "diff sampled tensor(33843.2188)\n",
      "epoch 0 loss 4.978695305026307 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.78', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.77']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8285168069474625\n",
      "diff sampled tensor(11041.3545)\n",
      "epoch 0 loss 1.6309005581602758 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.77', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8004055743535685\n",
      "diff sampled tensor(22447.3398)\n",
      "epoch 0 loss 3.4792921494464486 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.74', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.74', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.6']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.0630242795711109e-10 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 9.888220549909249e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953339\n",
      "diff sampled tensor(0.3002)\n",
      "epoch 0 loss 2.7007477024663063e-06 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.3002)\n",
      "epoch 0 loss 2.700773824917447e-06 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999996423721278\n",
      "diff sampled tensor(0.1785)\n",
      "epoch 0 loss 6.767456453621425e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.1785)\n",
      "epoch 0 loss 6.760417410096496e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.86', '0.86']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.86', '0.86']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.86', '0.86']\n",
      "totalscore 0.9999994635582574\n",
      "diff sampled tensor(0.0492)\n",
      "epoch 0 loss 6.083929088627159e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0492)\n",
      "epoch 0 loss 6.079274109132322e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.92', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.92', '0.91']\n",
      "totalscore 0.9999994635582574\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9655172413793104\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net014\n",
      "totalscore 0.9187271434934261\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.896551724137931\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net015\n",
      "totalscore 0.9095188864664169\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9310344827586207\n",
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net016\n",
      "totalscore 0.8635538708373827\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.9655172413793104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net017\n",
      "totalscore 0.8579245121747873\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.91']\n",
      "totalscore 0.8579245121747873\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291, 1000) (291,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 3, 224, 224)\n",
      "accuracy 0.896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276344_result_food101/set2_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net018\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.64', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.64', '0.45']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.3008999106426003e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.7', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.9843)\n",
      "epoch 0 loss 2.2261238872052133e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(2.5037)\n",
      "epoch 0 loss 6.077382899585078e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(2.6982)\n",
      "epoch 0 loss 2.670987457665377e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(5.2510)\n",
      "epoch 0 loss 5.267415627360829e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.72', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.71']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(7.5256)\n",
      "epoch 0 loss 7.670404634804331e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.67']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(3.8701)\n",
      "epoch 0 loss 157201.67547251418 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.44', '0.43', '0.42']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.44', '0.42']\n",
      "potential next fragments after thresholding of 0.8: 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 27, 27)\n",
      "(32, 192, 13, 13)\n",
      "(32, 384, 13, 13)\n",
      "(32, 256, 13, 13)\n",
      "(32, 9216)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "current depth: 1\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)(32, 16, 56, 56)\n",
      "\n",
      "(32, 64, 56, 56)\n",
      "(32, 16, 56, 56)\n",
      "(32, 256, 56, 56)(32, 64, 224, 224)\n",
      "(32, 256, 56, 56)(32, 72, 28, 28)\n",
      "\n",
      "\n",
      "(32, 64, 112, 112)(32, 24, 28, 28)\n",
      "\n",
      "(32, 96, 14, 14)\n",
      "(32, 512, 28, 28)\n",
      "(32, 128, 112, 112)(32, 512, 28, 28)(32, 40, 14, 14)\n",
      "\n",
      "\n",
      "(32, 120, 14, 14)\n",
      "(32, 128, 56, 56)(32, 48, 14, 14)\n",
      "\n",
      "(32, 1024, 14, 14)(32, 288, 7, 7)\n",
      "\n",
      "(32, 1024, 14, 14)\n",
      "(32, 256, 56, 56)\n",
      "(32, 2048)\n",
      "(32, 256, 56, 56)(32, 1024)(32, 96, 7, 7)\n",
      "\n",
      "\n",
      "(32, 576)\n",
      "(32, 1024)(32, 256, 28, 28)\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 512, 28, 28)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 25088)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.55', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.55', '0.55']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 6.910898389145469e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.57', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.57', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(0.0020)\n",
      "epoch 0 loss 1.8252158096558194e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.82', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.82', '0.8']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.82', '0.8']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(0.0678)\n",
      "epoch 0 loss 9.094009495522144e-06 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.76']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906962\n",
      "diff sampled tensor(0.1705)\n",
      "epoch 0 loss 2.589136067248837e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.95']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.95']\n",
      "totalscore 0.9999998807906962\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.94']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999998807906962\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.92']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906962\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 83.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.9032258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net000\n",
      "totalscore 0.9629149481159237\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 86.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.8387096774193549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net001\n",
      "totalscore 0.945360786275743\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.8153767585754279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 384]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.94']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.8153767585754279\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.92']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.8153766613749438\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 113.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.8387096774193549\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net002\n",
      "totalscore 0.800863385200489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 384]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.91']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.91']\n",
      "totalscore 0.800863385200489\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 95.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.7096774193548387\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net003\n",
      "current depth: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.68', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.68', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 6.15240578508657e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.76']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0257)\n",
      "epoch 0 loss 8.242122745212661e-07 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.88', '0.86']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.88', '0.86']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.88', '0.86']\n",
      "totalscore 0.9999998211860728\n",
      "diff sampled tensor(0.0073)\n",
      "epoch 0 loss 8.084293303723751e-07 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.9', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.9', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.9', '0.88']\n",
      "totalscore 0.9999998211860728\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net004\n",
      "totalscore 0.8950615116843635\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9354838709677419\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net005\n",
      "totalscore 0.8844782916644071\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9354838709677419\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net006\n",
      "totalscore 0.8758976533473906\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.967741935483871\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net007\n",
      "totalscore 0.8634270511014996\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.8634270511014996\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.967741935483871\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net008\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.97', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.97', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.97']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 7.565415938715778e-13 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.51']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.51']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(1.6273e-06)\n",
      "epoch 0 loss 5.001269386051107e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.57', '0.53']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185933\n",
      "diff sampled tensor(1.8509e-07)\n",
      "epoch 0 loss 4.679538049573779e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.58', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.58', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185933\n",
      "diff sampled tensor(9.6629e-06)\n",
      "epoch 0 loss 3.1301168120030956e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.63', '0.59']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.63']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(3.2387e-07)\n",
      "epoch 0 loss 7.301119799443982e-11 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.81', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.81']\n",
      "totalscore 1.000000119209279\n",
      "diff sampled tensor(3.5211e-06)\n",
      "epoch 0 loss 5.237046624026974e-10 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.77']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.000000119209279\n",
      "diff sampled tensor(1.2103e-06)\n",
      "epoch 0 loss 2.0235803962192704e-10 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.77', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.000000119209279\n",
      "diff sampled tensor(0.0014)\n",
      "epoch 0 loss 1.841460024646652e-07 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.000000119209279\n",
      "diff sampled tensor(8.6095e-06)\n",
      "epoch 0 loss 5.216053983294656e-10 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.8']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.8']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.9999999999999751\n",
      "diff sampled tensor(2.5374e-05)\n",
      "epoch 0 loss 9.431664809700142e-09 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.92', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.92', '0.85']\n",
      "totalscore 1.0000001192092647\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.91', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 1.0000001192092647\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net009\n",
      "totalscore 0.8844623427941862\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8709677419354839\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net010\n",
      "totalscore 0.920196831226326\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.967741935483871\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net011\n",
      "totalscore 0.850033402442911\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8709677419354839\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net012\n",
      "totalscore 0.8691428743770949\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.8691428225721426\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 641, in adjust_w\n",
      "    return adjust_w_conv(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 617, in adjust_w_conv\n",
      "    print('diff sampled', (acts1sampled - acts2sampled).pow(2).sum())\n",
      "RuntimeError: The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9032258064516129\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net013\n",
      "totalscore 0.8058979760225711\n",
      "ERROR The size of tensor a (40) must match the size of tensor b (120) at non-singleton dimension 1\n",
      "totalscore 0.970750629901886\n",
      "diff sampled tensor(3044955.7500)\n",
      "epoch 0 loss 0.7088940946423278 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.63', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.63']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.9542445521240168\n",
      "diff sampled tensor(20561.2324)\n",
      "epoch 0 loss 0.528962527002607 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.59', '0.47']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.59', '0.47']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.9248131100733941\n",
      "diff sampled tensor(70745.9062)\n",
      "epoch 0 loss 2.491003386828364 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.61', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.9064788173463366\n",
      "diff sampled tensor(3945.4915)\n",
      "epoch 0 loss 0.4503169449008241 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.76', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.76', '0.66']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8749122349473981\n",
      "diff sampled tensor(29685.7109)\n",
      "epoch 0 loss 4.423601189438178 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.76', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.844784967608341\n",
      "diff sampled tensor(10346.0869)\n",
      "epoch 0 loss 1.5380370665569694 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.96', '0.75', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 1 ['0.96']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.96']\n",
      "totalscore 0.8140893605571581\n",
      "diff sampled tensor(21515.2715)\n",
      "epoch 0 loss 3.333245725047832 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.73', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.73', '0.71']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.65', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.65', '0.54']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 9.37465727212072e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.0819187389808666e-10 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.69', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.0194)\n",
      "epoch 0 loss 1.740569561315986e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0194)\n",
      "epoch 0 loss 1.7405614161760946e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.66', '0.65']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.66', '0.65']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.0567)\n",
      "epoch 0 loss 1.875039673422532e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0567)\n",
      "epoch 0 loss 1.8758639261974094e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.87', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.87', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.87', '0.87']\n",
      "totalscore 0.9999997615814351\n",
      "diff sampled tensor(0.0268)\n",
      "epoch 0 loss 3.3140039129054403e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0268)\n",
      "epoch 0 loss 3.3166493174539197e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.89', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.89', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.89', '0.87']\n",
      "totalscore 0.9999997615814351\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8709677419354839\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net014\n",
      "totalscore 0.8946078074913103\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9032258064516129\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net015\n",
      "totalscore 0.8734553161965675\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9032258064516129\n",
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net016\n",
      "totalscore 0.8705127393588015\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.9032258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net017\n",
      "totalscore 0.8662327091416344\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.92', '0.88']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.88']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.88']\n",
      "totalscore 0.8662327091416344\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 1000) (307,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 224, 224)\n",
      "accuracy 0.9354838709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689276794_result_food101/set3_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net018\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.65', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.65', '0.45']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.1464026683958476e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.67', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.67', '0.67']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.8659)\n",
      "epoch 0 loss 1.9531328168030233e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(2.1833)\n",
      "epoch 0 loss 5.327122359668298e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(2.3750)\n",
      "epoch 0 loss 2.353913393507151e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(4.6034)\n",
      "epoch 0 loss 4.598385073352672e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.72', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(6.5674)\n",
      "epoch 0 loss 6.758390536189687e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.69', '0.66']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.66']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.999999940395341\n",
      "diff sampled tensor(3.5457)\n",
      "epoch 0 loss 2239908022844.214 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.49', '0.42', '0.36']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.49', '0.42']\n",
      "potential next fragments after thresholding of 0.8: 0 []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 27, 27)\n",
      "(32, 192, 13, 13)\n",
      "(32, 384, 13, 13)\n",
      "(32, 256, 13, 13)\n",
      "(32, 9216)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "current depth: 1\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)(32, 3, 224, 224)\n",
      "\n",
      "(32, 3, 224, 224)\n",
      "(32, 64, 56, 56)\n",
      "(32, 16, 56, 56)(32, 64, 224, 224)\n",
      "(32, 256, 56, 56)\n",
      "\n",
      "(32, 16, 56, 56)\n",
      "(32, 64, 112, 112)(32, 72, 28, 28)(32, 256, 56, 56)\n",
      "\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 128, 112, 112)\n",
      "(32, 24, 28, 28)(32, 1024, 14, 14)\n",
      "(32, 128, 56, 56)\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 96, 14, 14)(32, 256, 56, 56)\n",
      "(32, 1024)\n",
      "\n",
      "(32, 1024, 14, 14)(32, 256, 56, 56)\n",
      "\n",
      "(32, 40, 14, 14)\n",
      "(32, 120, 14, 14)\n",
      "(32, 256, 28, 28)(32, 2048)\n",
      "\n",
      "(32, 48, 14, 14)\n",
      "(32, 512, 28, 28)(32, 288, 7, 7)\n",
      "\n",
      "(32, 512, 28, 28)\n",
      "(32, 96, 7, 7)(32, 512, 14, 14)\n",
      "\n",
      "(32, 576)(32, 512, 14, 14)\n",
      "\n",
      "(32, 1024)\n",
      "(32, 512, 14, 14)\n",
      "(32, 25088)\n",
      "(32, 4096)\n",
      "(32, 4096)\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.58', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.58', '0.56']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 7.816795465748518e-11 torch.Size([23328, 64]) torch.Size([23328, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.55', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.55', '0.54']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000001192092896\n",
      "diff sampled tensor(0.0100)\n",
      "epoch 0 loss 4.77508063922008e-07 torch.Size([5408, 192]) torch.Size([5408, 192])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.75']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000002384185933\n",
      "diff sampled tensor(0.1175)\n",
      "epoch 0 loss 1.5143296797070984e-05 torch.Size([5408, 384]) torch.Size([5408, 384])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.81', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.81']\n",
      "totalscore 1.0000001788139343\n",
      "diff sampled tensor(0.2178)\n",
      "epoch 0 loss 3.284088559118072e-05 torch.Size([5408, 256]) torch.Size([5408, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.95']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.95']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.95']\n",
      "totalscore 1.0000002980232452\n",
      "epoch 0 loss 0.0 torch.Size([32, 9216]) torch.Size([32, 9216])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.9']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.94']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.94']\n",
      "totalscore 1.0000002980232452\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000004172325703\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 79.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n",
      "accuracy 0.6486486486486487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net000\n",
      "totalscore 0.9354920791065298\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 81.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n",
      "accuracy 0.7027027027027027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net001\n",
      "totalscore 0.9534152662900262\n",
      "ERROR unsupport linear to conv stitching\n",
      "totalscore 0.8114200380849583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1121, in recursive_stitching\n",
      "    newcurr_fragment = stitch_fragments(curr, nextf, data)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 740, in stitch_fragments\n",
      "    nw = adjust_w(tX, tY, w)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 639, in adjust_w\n",
      "    raise Exception(\"unsupport linear to conv stitching\")\n",
      "Exception: unsupport linear to conv stitching\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0 torch.Size([32, 256]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8114198929917489\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 93.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n",
      "accuracy 0.6756756756756757\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.68', '0.61']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.68', '0.61']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 5.337197456948567e-11 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.8', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.8', '0.76']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.0270)\n",
      "epoch 0 loss 8.720296475484229e-07 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.85', '0.83']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.85', '0.83']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.85', '0.83']\n",
      "totalscore 0.999999880790714\n",
      "diff sampled tensor(0.0074)\n",
      "epoch 0 loss 7.961348830799487e-07 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.89', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.89', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.89', '0.87']\n",
      "totalscore 0.999999880790714\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7837837837837838\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net003\n",
      "totalscore 0.8885966672185961\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net004\n",
      "totalscore 0.8674111524330104\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7837837837837838\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net005\n",
      "totalscore 0.8450471255155101\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8378378378378378\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net006\n",
      "totalscore 0.8276574714387941\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8276573727743349\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8108108108108109\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net007\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.47']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.93', '0.47']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.93']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.0580262274377357e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.55']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(2.3096e-06)\n",
      "epoch 0 loss 4.3940153408698405e-12 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.58', '0.53']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.58']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999403953552\n",
      "diff sampled tensor(1.5553e-07)\n",
      "epoch 0 loss 4.2692559238399987e-11 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.59', '0.48']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.59', '0.48']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0000000596046377\n",
      "diff sampled tensor(2.0717e-05)\n",
      "epoch 0 loss 5.556417435003329e-10 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.65', '0.57']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.65', '0.57']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(4.6450e-07)\n",
      "epoch 0 loss 9.221866920887984e-11 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.68']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.68']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(4.8405e-06)\n",
      "epoch 0 loss 7.112506774019169e-10 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.79']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(1.6977e-06)\n",
      "epoch 0 loss 2.8557912950521784e-10 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.79', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999893\n",
      "diff sampled tensor(3.9021e-06)\n",
      "epoch 0 loss 6.031460319850711e-10 torch.Size([6272, 48]) torch.Size([6272, 48])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.81', '0.7']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.81', '0.7']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.81']\n",
      "totalscore 0.9999998807906998\n",
      "diff sampled tensor(6.0759e-08)\n",
      "epoch 0 loss 3.067280896394035e-11 torch.Size([1568, 288]) torch.Size([1568, 288])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.85', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.85', '0.76']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.85']\n",
      "totalscore 0.9999998807906998\n",
      "diff sampled tensor(2.0623e-06)\n",
      "epoch 0 loss 7.08086433025194e-10 torch.Size([1568, 96]) torch.Size([1568, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.82']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.94', '0.82']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.94', '0.82']\n",
      "totalscore 0.9999998807906998\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.9999997615814245\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7567567567567568\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net008\n",
      "totalscore 0.8674130597814035\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8378378378378378\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net009\n",
      "totalscore 0.9365772680547877\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net010\n",
      "totalscore 0.8170384386731853\n",
      "epoch 0 loss 0.0 torch.Size([32, 576]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7567567567567568\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net011\n",
      "totalscore 0.849822181484418\n",
      "epoch 0 loss 0.0 torch.Size([32, 96]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.94', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8498220801777195\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 16.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8648648648648649\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net012\n",
      "totalscore 0.8067402243614111\n",
      "epoch 0 loss 0.0 torch.Size([32, 288]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.93', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8067400801050176\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 25.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7027027027027027\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net013\n",
      "totalscore 0.9266080856323242\n",
      "diff sampled tensor(2567317.5000)\n",
      "epoch 0 loss 0.47220437228679657 torch.Size([100352, 16]) torch.Size([100352, 16])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.66', '0.55']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.98', '0.55']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.9105791927211158\n",
      "diff sampled tensor(14093.4326)\n",
      "epoch 0 loss 0.3617310657793162 torch.Size([25088, 72]) torch.Size([25088, 72])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.59', '0.44']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.59', '0.44']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8852276744118049\n",
      "diff sampled tensor(54888.1484)\n",
      "epoch 0 loss 1.9538229387633654 torch.Size([25088, 24]) torch.Size([25088, 24])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.98', '0.63', '0.56']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.98', '0.63', '0.56']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.98']\n",
      "totalscore 0.8718500234748023\n",
      "diff sampled tensor(3218.6431)\n",
      "epoch 0 loss 0.36275054483997576 torch.Size([6272, 96]) torch.Size([6272, 96])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.76', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 3 ['0.97', '0.76', '0.67']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8444003787065726\n",
      "diff sampled tensor(26133.)\n",
      "epoch 0 loss 3.883345856958506 torch.Size([6272, 40]) torch.Size([6272, 40])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.77', '0.77']\n",
      "potential next fragments after filter duplicated fragments: 2 ['0.97', '0.77']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "totalscore 0.8197381352706158\n",
      "diff sampled tensor(8831.1035)\n",
      "epoch 0 loss 1.3090358656279895 torch.Size([6272, 120]) torch.Size([6272, 120])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['0.97', '0.75', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 1 ['0.97']\n",
      "potential next fragments after thresholding of 0.8: 1 ['0.97']\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.66', '0.54']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.66', '0.54']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 1.0\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 8.427386431837969e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 9.262662519080091e-11 torch.Size([100352, 64]) torch.Size([100352, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.68', '0.6']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.68', '0.6']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.0577)\n",
      "epoch 0 loss 4.1771565812658604e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "diff sampled tensor(0.0577)\n",
      "epoch 0 loss 4.1771425415214366e-07 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.0573)\n",
      "epoch 0 loss 2.0497060195710365e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "diff sampled tensor(0.0573)\n",
      "epoch 0 loss 2.049007527640075e-06 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.83', '0.81']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.83', '0.81']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.83', '0.81']\n",
      "totalscore 0.9999996423721598\n",
      "diff sampled tensor(0.0267)\n",
      "epoch 0 loss 3.3309452748876446e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "diff sampled tensor(0.0267)\n",
      "epoch 0 loss 3.3253531817498866e-06 torch.Size([6272, 1024]) torch.Size([6272, 1024])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.89', '0.85']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.89', '0.85']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.89', '0.85']\n",
      "totalscore 0.9999996423721598\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7837837837837838\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net014\n",
      "totalscore 0.885432820761299\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8918918918918919\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net015\n",
      "totalscore 0.8479685134999456\n",
      "epoch 0 loss 0.0 torch.Size([32, 2048]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7567567567567568\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net016\n",
      "totalscore 0.8318897686135927\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 576])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.95', '0.87']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.87']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.87']\n",
      "totalscore 0.8318897686135927\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net017\n",
      "totalscore 0.810301326477358\n",
      "epoch 0 loss 0.0 torch.Size([32, 1024]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net018\n",
      "current depth: 1\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.6', '0.45']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.6', '0.45']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807907104\n",
      "diff sampled tensor(0.)\n",
      "epoch 0 loss 1.1648531996573935e-06 torch.Size([1605632, 64]) torch.Size([1605632, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 2\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.67', '0.62']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.67', '0.62']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(1.0149)\n",
      "epoch 0 loss 2.245830358145547e-06 torch.Size([401408, 64]) torch.Size([401408, 64])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 3\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.72', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.72']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(2.6088)\n",
      "epoch 0 loss 6.320685271503509e-06 torch.Size([401408, 128]) torch.Size([401408, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 4\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.75', '0.72']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.75']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999999999999858\n",
      "diff sampled tensor(2.8440)\n",
      "epoch 0 loss 2.801691460968423e-05 torch.Size([100352, 128]) torch.Size([100352, 128])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 5\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.999999940395341\n",
      "diff sampled tensor(5.6420)\n",
      "epoch 0 loss 5.6204120594383295e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 6\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.73', '0.71']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.71']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.999999940395341\n",
      "diff sampled tensor(8.2437)\n",
      "epoch 0 loss 8.373948671482028e-05 torch.Size([100352, 256]) torch.Size([100352, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 7\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.7', '0.67']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.67']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999998807906998\n",
      "diff sampled tensor(4.4030)\n",
      "epoch 0 loss 0.0009581143427307584 torch.Size([25088, 256]) torch.Size([25088, 256])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 8\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997019767868\n",
      "diff sampled tensor(50.3995)\n",
      "epoch 0 loss 0.001027679163487438 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 9\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.74', '0.69']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.74', '0.69']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999997019767868\n",
      "diff sampled tensor(10.7375)\n",
      "epoch 0 loss 0.0003962713384012483 torch.Size([25088, 512]) torch.Size([25088, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 10\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.73']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.73']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999995231629057\n",
      "diff sampled tensor(1.7322)\n",
      "epoch 0 loss 0.00023621487507254494 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 11\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.74']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.74']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999993443490567\n",
      "diff sampled tensor(1.4189)\n",
      "epoch 0 loss 0.00018183037410585248 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 12\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.78', '0.76']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.78', '0.76']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999993443490567\n",
      "diff sampled tensor(0.9490)\n",
      "epoch 0 loss 0.0001174607266652949 torch.Size([6272, 512]) torch.Size([6272, 512])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 13\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.96']\n",
      "potential next fragments after filter duplicated fragments: 1 ['1.0']\n",
      "potential next fragments after thresholding of 0.8: 1 ['1.0']\n",
      "totalscore 0.9999993443490567\n",
      "epoch 0 loss 0.0 torch.Size([32, 25088]) torch.Size([32, 25088])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 14\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.96', '0.91']\n",
      "potential next fragments after filter duplicated fragments: 2 ['1.0', '0.96']\n",
      "potential next fragments after thresholding of 0.8: 2 ['1.0', '0.96']\n",
      "totalscore 0.9999994635582681\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n",
      "(32, 3, 224, 224)\n",
      "current depth: 15\n",
      "potential next fragments: 3\n",
      "potential next fragments before thresholding of 0.8: 3 ['1.0', '0.85', '0.84']\n",
      "potential next fragments after filter duplicated fragments: 3 ['1.0', '0.85', '0.84']\n",
      "potential next fragments after thresholding of 0.8: 3 ['1.0', '0.85', '0.84']\n",
      "totalscore 0.9999994635582681\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7297297297297297\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net019\n",
      "totalscore 0.8487454868130405\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7027027027027027\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net020\n",
      "totalscore 0.836847094796485\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7567567567567568\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net021\n",
      "totalscore 0.9597076441771624\n",
      "epoch 0 loss 0.0 torch.Size([32, 4096]) torch.Size([32, 4096])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6486486486486487\n",
      "saving to _results/1689277241_result_food101/set4_CKA_BS_32_MD_16_T_0.8_TT_0.8_K_3/net022\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from stitchnet.stitchonnx.utils import run_experiment, get_stitching_data_from_dataset\n",
    "\n",
    "i = 0\n",
    "for i in range(5):\n",
    "    dataset_train = load_from_disk(f'./_data/food101_set{i}/train', keep_in_memory=True)\n",
    "    dataset_val = load_from_disk(f'./_data/food101_set{i}/validation', keep_in_memory=True)\n",
    "\n",
    "    RESULT_NAME = f\"{EXP_TIME}_result_food101/set{i}_CKA_BS_{STITCH_BATCH_SIZE}_MD_{MAX_DEPTH}_T_{THRESOULD}_TT_{TOTAL_THRESOULD}_K_{K}\"\n",
    "\n",
    "    data_score = get_stitching_data_from_dataset(dataset_train, batch_size=STITCH_BATCH_SIZE)\n",
    "\n",
    "    run_experiment(result_name=RESULT_NAME, \n",
    "                   nets=nets, \n",
    "                   data_score=data_score, \n",
    "                   dataset_val=dataset_val, \n",
    "                   dataset_train=dataset_train, \n",
    "                   scoring_method='CKA', \n",
    "                   branching_factor=K,\n",
    "                   threshold=THRESOULD, \n",
    "                   total_threshold=TOTAL_THRESOULD, \n",
    "                   max_depth=MAX_DEPTH, \n",
    "                   eval_batch_size=EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a76b0c-321f-456e-9fbf-431ff1aaaa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE RUNNING\n"
     ]
    }
   ],
   "source": [
    "print('DONE RUNNING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9e2691f-61b3-4d44-b8d7-35baf815f0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 16.69it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 27, 27)\n",
      "(32, 192, 13, 13)\n",
      "(32, 384, 13, 13)\n",
      "(32, 256, 13, 13)\n",
      "(32, 9216)\n",
      "(32, 4096)\n",
      "(32, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:01,  1.59s/it]\u001b[A\n",
      "2it [00:01,  1.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.4 input.4 1.0\n",
      "input.12 input.12 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:01,  2.24it/s]\u001b[A\n",
      "4it [00:01,  3.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_24 onnx::Conv_24 1.0000001192092896\n",
      "onnx::Conv_26 onnx::Conv_26 0.9999998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:04,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.32 input.32 0.9586372971534729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:06,  1.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_33 onnx::Gemm_33 0.9547525644302368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [00:07,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_35 onnx::Gemm_35 0.9221929907798767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:00.617305021 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.628328555 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.637646129 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.646715463 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.655437502 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.664192314 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.672889749 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 70%|███████   | 7/10 [00:00<00:00, 67.12it/s]\u001b[A2023-07-14 03:41:00.683633099 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.692785452 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "2023-07-14 03:41:00.711531015 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 36\n",
      "100%|██████████| 10/10 [00:00<00:00, 70.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:03.758152546 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]\u001b[A2023-07-14 03:41:03.869986743 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {5,1000} for output 36\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:08.052908327 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:09.866845642 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:11.711662415 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 30%|███       | 3/10 [00:05<00:12,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:13.522579473 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 40%|████      | 4/10 [00:07<00:10,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:15.337395184 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 50%|█████     | 5/10 [00:09<00:09,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:17.153255660 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 60%|██████    | 6/10 [00:10<00:07,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:18.989347986 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 70%|███████   | 7/10 [00:12<00:05,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:20.842714420 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 80%|████████  | 8/10 [00:14<00:03,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:22.677367415 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 36\n",
      "\n",
      " 90%|█████████ | 9/10 [00:16<00:01,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:23.309413765 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 36\n",
      "\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.71s/it]\u001b[A\n",
      "1it [00:35, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3, 224, 224)\n",
      "VALACC: 0.7837837837837838 TRAINACC: 0.7892976588628763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 256, 56, 56)\n",
      "(32, 512, 28, 28)\n",
      "(32, 1024, 14, 14)\n",
      "(32, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:01,  1.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_776 onnx::Conv_776 0.9999998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:01,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_866 onnx::Conv_866 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:01,  2.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_1040 onnx::Conv_1040 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:01,  2.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_1160 onnx::Gemm_1160 0.996445894241333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:28.627263967 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.13it/s]\u001b[A2023-07-14 03:41:28.651791705 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:28.686503919 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:28.721539959 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 40%|████      | 4/10 [00:00<00:00, 10.97it/s]\u001b[A2023-07-14 03:41:28.758778983 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:28.794036473 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:28.829467255 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 70%|███████   | 7/10 [00:00<00:00, 16.25it/s]\u001b[A2023-07-14 03:41:28.865822550 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:28.900492737 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "2023-07-14 03:41:29.198120197 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 1161\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:32.193668040 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:32.578373183 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {5,1000} for output 1161\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:36.774150915 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:38.628806647 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:40.495089400 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 30%|███       | 3/10 [00:05<00:13,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:42.349933302 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 40%|████      | 4/10 [00:07<00:11,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:44.210127029 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 50%|█████     | 5/10 [00:09<00:09,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:46.104699884 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 60%|██████    | 6/10 [00:11<00:07,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:47.971787270 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 70%|███████   | 7/10 [00:13<00:05,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:49.828271673 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 80%|████████  | 8/10 [00:14<00:03,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:51.695703303 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 1161\n",
      "\n",
      " 90%|█████████ | 9/10 [00:16<00:01,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:41:52.360667141 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 1161\n",
      "\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.75s/it]\u001b[A\n",
      "2it [01:04, 31.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3, 224, 224)\n",
      "VALACC: 0.7567567567567568 TRAINACC: 0.8060200668896321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 16, 56, 56)\n",
      "(32, 16, 56, 56)\n",
      "(32, 72, 28, 28)\n",
      "(32, 24, 28, 28)\n",
      "(32, 96, 14, 14)\n",
      "(32, 40, 14, 14)\n",
      "(32, 120, 14, 14)\n",
      "(32, 48, 14, 14)\n",
      "(32, 288, 7, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 96, 7, 7)\n",
      "(32, 576)\n",
      "(32, 1024)\n",
      "input.32 input.32 1.0\n",
      "input.40 input.40 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00,  4.38it/s]\u001b[A\n",
      "5it [00:00,  6.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_265 onnx::Conv_265 1.0\n",
      "onnx::Conv_276 onnx::Conv_276 1.0000001192092896\n",
      "input.120 input.120 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [00:01,  8.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_326 onnx::Conv_326 1.0\n",
      "input.244 input.244 1.0000001192092896\n",
      "onnx::Conv_359 onnx::Conv_359 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9it [00:01,  8.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.328 input.328 1.0\n",
      "onnx::Conv_409 onnx::Conv_409 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:01,  8.53it/s]\u001b[A\n",
      "12it [00:01,  6.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_415 onnx::Gemm_415 0.9999998807907104\n",
      "onnx::Gemm_418 onnx::Gemm_418 0.9991249442100525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:41:57.269672855 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 10%|█         | 1/10 [00:00<00:02,  3.61it/s]\u001b[A2023-07-14 03:41:57.282588575 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.292484755 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.302439439 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.312787372 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.322567697 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.332274560 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.341853375 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.351561801 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "2023-07-14 03:41:57.596644609 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 419\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.49it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A2023-07-14 03:42:01.035537044 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:01.373141163 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {5,1000} for output 419\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.16it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:42:05.786401219 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:07.602930031 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:09.426644237 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 30%|███       | 3/10 [00:05<00:12,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:11.241527804 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 40%|████      | 4/10 [00:07<00:10,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:13.070267240 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 50%|█████     | 5/10 [00:09<00:09,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:14.886937387 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 60%|██████    | 6/10 [00:10<00:07,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:16.708366417 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 70%|███████   | 7/10 [00:12<00:05,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:18.524629678 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 80%|████████  | 8/10 [00:14<00:03,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:20.341819991 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 419\n",
      "\n",
      " 90%|█████████ | 9/10 [00:16<00:01,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:20.976293344 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 419\n",
      "\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\u001b[A\n",
      "3it [01:32, 30.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3, 224, 224)\n",
      "VALACC: 0.8108108108108109 TRAINACC: 0.8394648829431438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 56, 56)\n",
      "(32, 256, 56, 56)\n",
      "(32, 512, 28, 28)\n",
      "(32, 1024, 14, 14)\n",
      "(32, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:01,  1.36s/it]\u001b[A\n",
      "2it [00:01,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.8 input.8 0.9999999403953552\n",
      "input.84 input.84 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:01,  1.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.184 input.184 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4it [00:02,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.332 input.332 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:03,  1.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_494 onnx::Gemm_494 0.9775843024253845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:42:27.874692428 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 10%|█         | 1/10 [00:00<00:01,  4.54it/s]\u001b[A2023-07-14 03:42:27.901230790 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:27.923816143 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:27.947907071 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:27.972581830 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 50%|█████     | 5/10 [00:00<00:00, 17.65it/s]\u001b[A2023-07-14 03:42:27.998932340 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:28.023261668 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:28.047408883 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:28.072001960 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "2023-07-14 03:42:28.215753109 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 495\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A2023-07-14 03:42:30.971965601 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:31.197048603 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {5,1000} for output 495\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:42:35.024996928 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:36.890486356 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:38.757164944 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 30%|███       | 3/10 [00:05<00:13,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:40.613681713 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 40%|████      | 4/10 [00:07<00:11,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:42.475651433 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 50%|█████     | 5/10 [00:09<00:09,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:44.343080344 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 60%|██████    | 6/10 [00:11<00:07,  1.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:46.239938535 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 70%|███████   | 7/10 [00:13<00:05,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:48.124851961 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 80%|████████  | 8/10 [00:14<00:03,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:50.015151036 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 495\n",
      "\n",
      " 90%|█████████ | 9/10 [00:16<00:01,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:42:50.672903178 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 495\n",
      "\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.75s/it]\u001b[A\n",
      "4it [02:02, 30.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3, 224, 224)\n",
      "VALACC: 0.8378378378378378 TRAINACC: 0.8361204013377926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(32, 64, 224, 224)\n",
      "(32, 64, 112, 112)\n",
      "(32, 128, 112, 112)\n",
      "(32, 128, 56, 56)\n",
      "(32, 256, 56, 56)\n",
      "(32, 256, 56, 56)\n",
      "(32, 256, 28, 28)\n",
      "(32, 512, 28, 28)\n",
      "(32, 512, 28, 28)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 512, 14, 14)\n",
      "(32, 25088)\n",
      "(32, 4096)\n",
      "(32, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:07,  7.33s/it]\u001b[A\n",
      "2it [00:07,  3.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_34 onnx::Conv_34 0.9999999403953552\n",
      "input.8 input.8 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:07,  1.77s/it]\u001b[A\n",
      "4it [00:07,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_39 onnx::Conv_39 1.0\n",
      "input.20 input.20 1.0000001192092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "5it [00:07,  1.29it/s]\u001b[A\n",
      "6it [00:08,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_44 onnx::Conv_44 0.9999999403953552\n",
      "onnx::Conv_46 onnx::Conv_46 0.9999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "7it [00:08,  2.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.36 input.36 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:08,  2.50it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_51 onnx::Conv_51 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9it [00:08,  2.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_53 onnx::Conv_53 1.0000001192092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10it [00:09,  2.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.52 input.52 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [00:09,  2.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_58 onnx::Conv_58 0.9999998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "12it [00:10,  2.53it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Conv_60 onnx::Conv_60 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "13it [00:24,  4.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_65 onnx::Gemm_65 0.9020739197731018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "14it [00:30,  4.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_67 onnx::Gemm_67 0.9546472430229187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "15it [00:32,  2.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx::Gemm_69 onnx::Gemm_69 0.9468382000923157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:43:30.423400105 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 10%|█         | 1/10 [00:00<00:04,  1.97it/s]\u001b[A2023-07-14 03:43:30.443510995 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "2023-07-14 03:43:30.497369717 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 30%|███       | 3/10 [00:00<00:01,  5.69it/s]\u001b[A2023-07-14 03:43:30.556682838 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "2023-07-14 03:43:30.611494324 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 50%|█████     | 5/10 [00:00<00:00,  8.72it/s]\u001b[A2023-07-14 03:43:30.669366391 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "2023-07-14 03:43:30.725672633 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 70%|███████   | 7/10 [00:00<00:00, 11.09it/s]\u001b[A2023-07-14 03:43:30.782445709 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "2023-07-14 03:43:30.837964475 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 90%|█████████ | 9/10 [00:00<00:00, 12.91it/s]\u001b[A2023-07-14 03:43:31.029859870 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 70\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 1000) (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A2023-07-14 03:43:33.229717310 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 50%|█████     | 1/2 [00:00<00:00,  1.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n",
      "(5, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:33.453158802 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {5,1000} for output 70\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.43it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A2023-07-14 03:43:37.431345891 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 10%|█         | 1/10 [00:01<00:16,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:39.304673243 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 20%|██        | 2/10 [00:03<00:14,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:41.186042270 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 30%|███       | 3/10 [00:05<00:13,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:43.062734462 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 40%|████      | 4/10 [00:07<00:11,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:44.933540769 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 50%|█████     | 5/10 [00:09<00:09,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:46.805021883 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 60%|██████    | 6/10 [00:11<00:07,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:48.684298582 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 70%|███████   | 7/10 [00:13<00:05,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:50.597053625 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 80%|████████  | 8/10 [00:15<00:03,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:52.479974427 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {32,1000} for output 70\n",
      "\n",
      " 90%|█████████ | 9/10 [00:16<00:01,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 03:43:53.160764878 [W:onnxruntime:, execution_frame.cc:812 VerifyOutputSizes] Expected shape from model of {1,1000} does not match actual shape of {11,1000} for output 70\n",
      "\n",
      "100%|██████████| 10/10 [00:17<00:00,  1.76s/it]\u001b[A\n",
      "5it [03:04, 41.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 3, 224, 224)\n",
      "VALACC: 0.7567567567567568 TRAINACC: 0.8060200668896321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_99 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_101 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_102 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_171 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_173 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_174 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_243 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_245 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_246 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_315 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_317 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_318 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_387 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_389 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_390 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_459 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_461 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_462 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_531 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_533 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_534 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_603 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_605 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_606 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_675 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_677 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_678 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_747 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_749 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_750 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_819 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_821 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_822 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_891 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_893 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnx_tool/node_profilers.py:1127: UserWarning: node Reshape_894 cannot reshape array of size (197,1,2304,) into shape (197,12,64,) \n",
      "  warnings.warn(f'node {self.name} cannot reshape array of size {tuple2str(srcshape)} into shape {tuple2str(shape)} ')\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5it [03:06, 37.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1462643/1042804037.py\", line 40, in <cell line: 8>\n",
      "    valacc, trainacc = evaluate_net(net, dataset_train, dataset_val, label_column=label_column)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/utils.py\", line 1652, in evaluate_net\n",
      "    pipe = NetEvalPipeline(dataset_train, net, label=label_column)\n",
      "  File \"/home/jupyter-steerapi/stitchnet/stitchnet/stitchonnx/report.py\", line 80, in __init__\n",
      "    self.ort_sess1 = ort.InferenceSession(fragmentC.fragment.SerializeToString(), providers=['CUDAExecutionProvider'])\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 347, in __init__\n",
      "    self._create_inference_session(providers, provider_options, disabled_optimizers)\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 386, in _create_inference_session\n",
      "    sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)\n",
      "onnxruntime.capi.onnxruntime_pybind11_state.Fail: [ONNXRuntimeError] : 1 : FAIL : Type Error: Type (tensor(float)) of output arg (onnx::Reshape_1900) of node (Identity_0) does not match expected type (tensor(int64)).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/jupyter-steerapi/.conda/envs/stitchnet/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "from datasets import load_from_disk\n",
    "from stitchnet.stitchonnx.report import NetEvalPipeline\n",
    "from stitchnet.stitchonnx.utils import evaluate_net, load_dl, get_stitching_data_from_dataset, get_macs_params_onnx, get_score_net\n",
    "from stitchnet.stitchonnx.viz import draw_stitchNet_fromTuples\n",
    "\n",
    "# evaluate original networks\n",
    "for setI in range(5):\n",
    "    dataset_train = load_from_disk(f'./_data/food101_set{setI}/train', keep_in_memory=True)\n",
    "    dataset_val = load_from_disk(f'./_data/food101_set{setI}/validation', keep_in_memory=True)\n",
    "\n",
    "    data_score = get_stitching_data_from_dataset(dataset_train, batch_size=STITCH_BATCH_SIZE)\n",
    "\n",
    "    RESULT_NAME = f\"_results/{EXP_TIME}_result_food101/set{setI}_original\"\n",
    "    os.makedirs(RESULT_NAME, exist_ok=True)\n",
    "\n",
    "    modelnames = sorted(glob('_models/*.onnx'))\n",
    "    for i,modelname in tqdm(enumerate(modelnames)):\n",
    "        name = os.path.basename(modelname)\n",
    "        namewithoutext = os.path.splitext(name)[0]\n",
    "\n",
    "        model_onnx1 = load_onnx_model(modelname)\n",
    "        macs, params = get_macs_params_onnx(model_onnx1)\n",
    "\n",
    "        # get CKA score of the original network, no stitching\n",
    "        fragmentFiles = sorted(glob(f'_models/fragments/net{i:03}/*.onnx'))\n",
    "        onnxFragments = []\n",
    "        js = []\n",
    "        for j,fragmentFile in enumerate(fragmentFiles):\n",
    "            onnxFragment = load_onnx_model(fragmentFile)\n",
    "            onnxFragments.append(onnxFragment)\n",
    "            js.append((i,j))\n",
    "        net1 = Net(onnxFragments, i)\n",
    "        score = get_score_net(net1, data_score)\n",
    "\n",
    "        net = Net([model_onnx1])\n",
    "        label_column = 'label'\n",
    "\n",
    "        # evaluate the original network\n",
    "        valacc, trainacc = evaluate_net(net, dataset_train, dataset_val, label_column=label_column)\n",
    "\n",
    "        print('VALACC:', valacc, 'TRAINACC:', trainacc)\n",
    "\n",
    "        with open(f'{RESULT_NAME}/{namewithoutext}.txt', 'w') as f:\n",
    "            f.write(f'{valacc},{trainacc},{macs},{params},{score},\"{tuple(js)}\"\\n')\n",
    "\n",
    "        draw_stitchNet_fromTuples(js, name=f'{RESULT_NAME}/{namewithoutext}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63dee8c5-909d-4f18-a547-5df0f56f4790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb5e71f2-1d9c-416f-b0ab-b90f1ebc76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # range(1)\n",
    "# def runExperiment():\n",
    "#     k = 0\n",
    "#     if os.path.exists(f'./_results/{RESULT_NAME}.txt'):\n",
    "#         with open(f'./_results/{RESULT_NAME}.txt', 'r') as f:\n",
    "#             k = len(f.read().split('\\n'))\n",
    "#     from tqdm import tqdm\n",
    "#     from stitchnet.stitchonnx.report import Report, ReportPlants, ReportKNNHFDataset\n",
    "#     import traceback\n",
    "#     scoreMapper = ScoreMapper(nets, data_score, scoring_method='CKA')\n",
    "#     with ReportKNNHFDataset(EVAL_BATCH_SIZE, f'./_results/{RESULT_NAME}.txt', 'a') as report:\n",
    "#         # for _ in tqdm(range(50)):\n",
    "#         generator = generate_networks(nets, scoreMapper, data_score, \n",
    "#                               threshold=THRESOULD, totalThreshold=TOTAL_THRESOULD, \n",
    "#                               maxDepth=MAX_DEPTH, sample=False, K=K)\n",
    "#         for i,(s,net) in enumerate(generator):\n",
    "#             try:\n",
    "#                 netname = f\"_results/{RESULT_NAME}/net{k:03}\"\n",
    "#                 report.evaluate(nets, net, netname, s, dataset_val, dataset_train)\n",
    "#                 net.save(netname)\n",
    "#                 k += 1\n",
    "#             except Exception as e:\n",
    "#                 print('ERROR', e)\n",
    "#                 traceback.print_exc()\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca26740c-821d-4501-a5f8-0ca4e10f7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7968d629-5495-42a0-9fad-2dceb6ec98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in dataset_train:\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29248219-866d-480a-a8e8-85332442f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in dl:\n",
    "#     print(x[0].squeeze(1).shape, x[1].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24ea698b-9d65-4751-aaaa-92b03594e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7948b22-19ef-4ec4-a6e9-4e2ff97806d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.evaluate(nets, net, netname, s, dataset_val, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "247a84f3-1e47-45a4-9c48-08ce3c379850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# ort.get_available_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "745ea6e0-ea56-4a2a-a8cd-c142e8636d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in dataset_train:\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab5d2633-6432-443e-b881-de99afb22330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stitchnet.stitchonnx.utils import accuracy_score_net_plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1359c6f1-ace7-4d29-90f1-955daa986281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([1,2]).numpy().tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f126de0f-ac3c-4e9e-911e-5c315a1cce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,t in dataset_val:\n",
    "#     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a392215-d1e5-400e-9722-6043a8075896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "77bdcdb0-9b81-415e-9c1d-167a511a14e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score_net_plants(net, dataset_val, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5f2ee5b-79e7-4031-8da9-370ba69998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# knn.fit(np.ones([100,10]), np.ones([100,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "71a77cd2-0240-4b22-b0c5-748156f96db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = knn.predict(np.ones([1,10]))\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f0e38c8-add9-4b3d-8fe1-726c3c2b20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0062065-28d9-4d1d-84c8-e337735b9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ca02b-b974-4eea-be3d-c7c40ac4148a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e1ce2-30c1-4741-be84-b9de165be464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stitchnet",
   "language": "python",
   "name": "stitchnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
